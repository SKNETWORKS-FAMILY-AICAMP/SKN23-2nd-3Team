from __future__ import annotations

from pathlib import Path
import json
import sys
import time

import numpy as np
import pandas as pd
import torch
import streamlit as st
import plotly.graph_objects as go

from utils.paths import DEFAULT_PATHS as P, ensure_runtime_dirs
from utils.ui import apply_base_layout, hide_sidebar, top_nav

# 0) Page Config
st.set_page_config(
    page_title="AI ì´íƒˆ ì˜ˆì¸¡ ì†”ë£¨ì…˜",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="collapsed",
)

apply_base_layout()
hide_sidebar()
top_nav()

# ==== CSS ìŠ¤íƒ€ì¼ë§ (ì œê³µí•´ì£¼ì‹  ìŠ¤íƒ€ì¼ ê·¸ëŒ€ë¡œ ìœ ì§€) =====
st.markdown("""
<style>
    .block-container { padding-top: 0.6rem !important; padding-bottom: 3rem; }
    h1 { padding-top: 0rem !important; margin-top: -2rem !important; }
    div[data-testid="stVerticalBlock"] { gap: 0.5rem !important; }
    
    .risk-badge {
        display: inline-block; padding: 0.3rem 1.2rem; border-radius: 50px;
        font-weight: 700; font-size: 0.85rem; margin-top: 0.3rem;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    .section-header {
        color: #dd2e1f; font-size: 1.25rem; font-weight: 700;
        margin-bottom: 1rem; padding-bottom: 0.5rem; border-bottom: 2px solid #dd2e1f;
    }
    .stButton>button {
        width: 100%; background: linear-gradient(135deg, #dd2e1f 20%, #ffdff6 100%);
        color: white; font-weight: 700; padding: 0.9rem 2rem; border-radius: 12px;
        border: none; font-size: 1.1rem; transition: all 0.3s ease;
        box-shadow: 0 4px 16px rgba(102,126,234,0.4);
    }
    .stButton>button:hover { transform: translateY(-2px); box-shadow: 0 6px 20px rgba(102,126,234,0.5); }
    
    .result-wrap {
        border-radius: 18px; padding: 0.6rem; box-shadow: 0 4px 15px rgba(0,0,0,0.08);
        margin: 0.2rem 0 1.0rem 0; border: 1px solid rgba(0,0,0,0.05);
    }
    
    /* [ìˆ˜ì •] ê°„ê²©(gap)ì„ 0.6rem -> 0.3remìœ¼ë¡œ ì¶•ì†Œ */
    .kpi-wrap { display:flex; flex-direction: column; align-items: flex-end; gap: 0.3rem; width: 100%; }
    
    /* [ìˆ˜ì •] ì¹´ë“œ íŒ¨ë”©ê³¼ ê¸€ì í¬ê¸° ì¶•ì†Œ */
    .stat-card-small {
        background: linear-gradient(135deg, #dd2e1f 20%, #670800 100%);
        color: white;
        padding: 0.4rem 0.5rem; /* íŒ¨ë”© ì¶•ì†Œ */
        border-radius: 12px;
        text-align: center;
        box-shadow: 0 4px 10px rgba(102,126,234,0.20);
        width: 100%; 
        margin-bottom: 0.2rem; /* ë§ˆì§„ ì¶•ì†Œ */
    }
    .stat-card-small .stat-label {
        font-size: 0.75rem; /* ë¼ë²¨ í°íŠ¸ ì¶•ì†Œ */
        font-weight: 700;
        opacity: 0.95;
        margin-bottom: 1px;
    }
    .stat-card-small .stat-value {
        font-size: 1.3rem; /* ê°’ í°íŠ¸ ì¶•ì†Œ */
        font-weight: 900;
    }
    
    div.row-widget.stRadio > div { flex-direction: row; gap: 20px; align-items: center; }
    
    .frame-head { display:flex; justify-content: space-between; align-items: center; gap: 1rem; margin: 0.2rem 0 0.35rem 0; }
    .frame-title { display: flex; align-items: center; gap: 0.5rem; color: #dd2e1f; font-size: 1.15rem; font-weight: 700; line-height: 1.1; }
    .frame-line { height: 6px; margin: 0.1rem 0 0.4rem 0; position: relative; }
    .frame-line::before { content: ""; position: absolute; left: 0; right: 0; top: 50%; height: 2px; background: #dd2e1f; transform: translateY(-50%); border-radius: 999px; opacity: 0.95; }
    
    .kpi-pane { border-left: 4px solid #dd2e1f; padding-left: 1.0rem; height: 100%; display: flex; flex-direction: column; justify-content: flex-start; }
</style>
""", unsafe_allow_html=True)


# ================================= ì œëª© ==============================
st.markdown(
    """
<style>
    @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@400;600;800&display=swap');
    
    .dashboard-header {
        position: relative;
        padding: 2.5rem 0 2rem 0;
        background: white;
        border-bottom: 1px solid #e5e7eb;
        margin-bottom: 2rem;
    }
    
    .header-content {
        position: relative;
        z-index: 1;
    }
    
    .main-title {
        font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, sans-serif;
        font-weight: 800;
        font-size: 2.5rem;
        background: linear-gradient(135deg, #dd2e1f 20%, #ffdff6 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        margin: 0;
        letter-spacing: -0.5px;
        animation: fadeInUp 0.6s ease-out;
    }
    
    .subtitle {
        font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, sans-serif;
        font-size: 1.1rem;
        color: #6b7280;
        margin: 0.75rem 0 0 0;
        font-weight: 500;
        letter-spacing: -0.2px;
        animation: fadeInUp 0.6s ease-out 0.1s both;
    }
    
    .accent-line {
        width: 60px;
        height: 4px;
        background: linear-gradient(135deg, #dd2e1f 20%, #ffdff6 100%);
        border-radius: 2px;
        margin-top: 1rem;
        animation: fadeInUp 0.6s ease-out 0.2s both;
    }
    
    @keyframes fadeInUp {
        from {
            opacity: 0;
            transform: translateY(20px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
</style>

<div class="dashboard-header">
    <div class="header-content">
        <h1 class="main-title">AI ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ</h1>
        <p class="subtitle">ë”¥ëŸ¬ë‹ MLP ëª¨ë¸ì„ ì´ìš©í•œ ì˜ˆì¸¡</p>
        <div class="accent-line"></div>
    </div>
</div>
""",
    unsafe_allow_html=True,
)



ensure_runtime_dirs()
sys.path.insert(0, str(P.root))


# 1) Paths / Config
DATA_PATH = P.parquet_path("features_ml_clean")
MODELS_DL_ROOT = P.models_dl_dir
PREP_ROOT = P.models_preprocessing_dir
EVAL_ROOT = P.models_eval_dir
METRICS_ROOT = P.models_metrics_dir

FEATURE_ORDER = [
    "n_events_30d", "active_days_30d", "n_purchase_30d", "purchase_ratio",
    "days_since_last_event", "days_since_last_purchase", "brand_concentration_ratio",
    "brand_switch_count_30d", "total_spend_30d", "activity_ratio_15d",
    "price_volatility", "n_events_7d", "visit_regularity", "activity_trend",
]
N_FEATURES = len(FEATURE_ORDER)

# 2) Helpers & Loaders
def read_json(path: Path):
    if not path.exists(): return None
    return json.loads(path.read_text(encoding="utf-8"))

def file_mtime(p: Path) -> float:
    return p.stat().st_mtime if p.exists() else -1.0

def must_exist_parquets_for_project() -> None:
    P.must_parquet_path("base")
    P.must_parquet_path("anchors")
    P.must_parquet_path("labels")
    P.must_parquet_path("features_ml_clean")

@st.cache_data
def load_feature_stats(data_path: Path, feature_order: list[str], data_mtime: float):
    df = pd.read_parquet(data_path)
    stats = {}
    for col in feature_order:
        s = df[col].dropna()
        if len(s) == 0:
            stats[col] = {"mean": 0.0, "std": 1.0}
            continue
        std = float(s.std())
        stats[col] = {"mean": float(s.mean()), "std": std if std != 0 else 1.0}
    return stats

def resolve_scaler_path(model_name: str, version: str) -> Path:
    cand = [
        PREP_ROOT / model_name / version / "scaler.pkl",
        PREP_ROOT / model_name / version / "scaler.joblib",
        PREP_ROOT / f"{model_name}_scaler.pkl",
        PREP_ROOT / f"{model_name}_scaler.joblib",
    ]
    for p in cand:
        if p.exists(): return p
    return cand[0]

def resolve_percentiles_path(model_id: str, model_name: str, version: str) -> Path:
    eval_dir = model_id.replace("__", "")
    cand = [
        METRICS_ROOT / f"{model_name}_{version}_score_percentiles.json",
        METRICS_ROOT / f"{model_name}_score_percentiles.json",
        METRICS_ROOT / f"{eval_dir}_{version}_score_percentiles.json",
        METRICS_ROOT / f"{eval_dir}_score_percentiles.json",
    ]
    for p in cand:
        if p.exists(): return p
    return cand[-1]

@st.cache_data
def load_topk_cutoffs(path: Path, path_mtime: float):
    payload = read_json(path)
    if not payload: return {}
    out = {}
    for row in payload.get("cutoffs_by_k", []):
        out[int(row["k_pct"])] = float(row["t_k"])
    if not out and isinstance(payload, dict):
        for k, v in payload.items():
            try: out[int(k)] = float(v)
            except: pass
    return out

@st.cache_data
def load_score_percentiles(path: Path, path_mtime: float):
    payload = read_json(path)
    if not payload: return None
    if isinstance(payload, list): return payload
    return payload.get("percentiles")

def percentile_label(prob: float, percentiles) -> str | None:
    if not percentiles: return None
    def get_thr(row: dict):
        for key in ("thr", "threshold", "score", "value", "t"):
            if key in row: return float(row[key])
        return None
    rows = []
    for r in percentiles:
        if not isinstance(r, dict) or "pct" not in r: continue
        thr = get_thr(r)
        if thr is None: continue
        rows.append((int(r["pct"]), float(thr)))
    if not rows: return None
    rows.sort(key=lambda x: x[0])
    for pct, thr in rows:
        if prob >= thr: return f"ìƒìœ„ {pct}%"
    return f"ìƒìœ„ {rows[-1][0]}% ë°–"

def risk_from_topk(prob: float, cutoffs: dict[int, float]):
    if not cutoffs: return ("Unknown", "#888", "âšª", "#f5f5f5", None)
    ks = sorted(cutoffs.keys())
    hit_k = None
    for k in ks:
        if prob >= float(cutoffs[k]):
            hit_k = k
            break
    if hit_k == 5: return ("High Risk", "#dc3545", "ğŸ”´", "#fff5f5", hit_k)
    if hit_k == 10: return ("Medium-High", "#ff6b6b", "ğŸŸ ", "#fff7f7", hit_k)
    if hit_k == 15: return ("Medium", "#ffc107", "ğŸŸ¡", "#fffbf0", hit_k)
    if hit_k == 30: return ("Low-Medium", "#28a745", "ğŸŸ¢", "#f0fff4", hit_k)
    return ("Low Risk", "#28a745", "ğŸŸ¢", "#f0fff4", None)

def _unwrap_state_dict(obj: object) -> dict:
    if isinstance(obj, dict) and "state_dict" in obj and isinstance(obj["state_dict"], dict):
        sd = obj["state_dict"]
    elif isinstance(obj, dict) and "model_state_dict" in obj and isinstance(obj["model_state_dict"], dict):
        sd = obj["model_state_dict"]
    elif isinstance(obj, dict):
        sd = obj
    else: raise ValueError("invalid checkpoint format")
    if any(k.startswith("module.") for k in sd.keys()):
        sd = {k.replace("module.", "", 1): v for k, v in sd.items()}
    return sd

def build_dl_model(model_name: str, input_dim: int):
    from models.model_definitions import MLP_base, MLP_enhance, MLP_advanced
    name_to_ctor = {"mlp_base": MLP_base, "mlp_enhance": MLP_enhance, "mlp_advanced": MLP_advanced}
    if model_name not in name_to_ctor: raise ValueError(f"Unknown DL model_name: {model_name}")
    return name_to_ctor[model_name](input_dim=input_dim)

@st.cache_resource
def load_fixed_dl_bundle(model_name: str, version: str):
    model_dir = MODELS_DL_ROOT / model_name / version
    if not model_dir.exists(): raise FileNotFoundError(f"DL model dir not found: {model_dir}")
    cand = [model_dir / "model.pt", model_dir / "weights.pt", model_dir / f"{model_name}.pt"]
    model_path = next((p for p in cand if p.exists()), None)
    if model_path is None: raise FileNotFoundError(f"DL weights not found")
    scaler_path = resolve_scaler_path(model_name, version)
    scaler = None
    if scaler_path.exists():
        import joblib
        scaler = joblib.load(scaler_path)
    
    model = build_dl_model(model_name=model_name, input_dim=N_FEATURES)
    ckpt = torch.load(model_path, map_location="cpu")
    state = _unwrap_state_dict(ckpt)
    
    new_state = {}
    for key, value in state.items():
        new_key = key
        if ".block.0." in key: new_key = key.replace(".block.0.", ".fc1.")
        elif ".block.1." in key: new_key = key.replace(".block.1.", ".bn1.")
        elif ".block.4." in key: new_key = key.replace(".block.4.", ".fc2.")
        elif ".block.5." in key: new_key = key.replace(".block.5.", ".bn2.")
        new_state[new_key] = value
    
    try:
        model.load_state_dict(new_state, strict=True)
    except RuntimeError as e:
        model.load_state_dict(new_state, strict=False)

    model.eval()
    return model, scaler, model_path, scaler_path

def predict_prob(model, x_df: pd.DataFrame) -> float:
    x_tensor = torch.from_numpy(x_df.to_numpy(dtype=np.float32))
    with torch.no_grad():
        logits = model(x_tensor)
        prob = torch.sigmoid(logits).item()
    return float(prob)


def _parse_int_optional(label: str, raw: str, min_v: int, max_v: int):
    raw = (raw or "").strip()
    if raw == "": return 0, None  
    try:
        if '.' in raw: return 0, f"{label}: ì •ìˆ˜ë§Œ ì…ë ¥í•´ì£¼ì„¸ìš”."
        v = int(float(raw))
    except:
        return 0, f"{label}: ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    if v < min_v or v > max_v:
        return 0, f"{label}: {min_v:,}~{max_v:,} ì‚¬ì´ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤." 
    return v, None

def _parse_float_optional(label: str, raw: str, min_v: float, max_v: float):
    raw = (raw or "").strip()
    if raw == "": return 0.0, None 
    try:
        v = float(raw)
    except:
        return 0.0, f"{label}: ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    if v < min_v or v > max_v:
        return 0.0, f"{label}: {min_v:,}~{max_v:,} ì‚¬ì´ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤."  
    return v, None

def input_int_placeholder(label: str, key: str, min_v: int, max_v: int):
    placeholder = f"ìˆ«ì ì…ë ¥ ({min_v:,}~{max_v:,})"
    
    if key in st.session_state:
        raw = st.text_input(label, key=key, placeholder=placeholder)
    else:
        raw = st.text_input(label, value="", key=key, placeholder=placeholder)
    
    val, err = _parse_int_optional(label, raw, min_v, max_v)
    if key == "n_purchase_30d_txt" and val >0:
        val -= 1

    return val, err

def input_float_placeholder(label: str, key: str, min_v: float, max_v: float):
    placeholder = f"ìˆ«ì ì…ë ¥ ({min_v:,}~{max_v:,})"
    if key in st.session_state:
        raw = st.text_input(label, key=key, placeholder=placeholder)
    else:
        raw = st.text_input(label, value="", key=key, placeholder=placeholder)
    return _parse_float_optional(label, raw, min_v, max_v)

# 5) íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
must_exist_parquets_for_project()
if not DATA_PATH.exists():
    st.error(f"features file not found: {DATA_PATH}")
    st.stop()

STATS = load_feature_stats(DATA_PATH, FEATURE_ORDER, file_mtime(DATA_PATH))
FIXED_MODEL_NAME = "mlp_advanced"
FIXED_VERSION = "baseline"
MODEL_ID = "dl__mlp_advanced"
EVAL_DIR_NAME = MODEL_ID.replace("__", "")
TOPK_PATH = EVAL_ROOT / EVAL_DIR_NAME / "topk_cutoffs.json"
PCTS_PATH = resolve_percentiles_path(MODEL_ID, FIXED_MODEL_NAME, FIXED_VERSION)
topk_cutoffs = load_topk_cutoffs(TOPK_PATH, file_mtime(TOPK_PATH))
pcts = load_score_percentiles(PCTS_PATH, file_mtime(PCTS_PATH))

try:
    model, scaler, model_path, scaler_path = load_fixed_dl_bundle(FIXED_MODEL_NAME, FIXED_VERSION)
except Exception as e:
    st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}"); st.stop()

# =============================================================================================================

PRESET_VALUES = {
    "Top 5%": {
        "n_events_30d_txt": "1", "active_days_30d_txt": "1", "days_since_last_event_txt": "24.375764",
        "n_purchase_30d_txt": "1", "total_spend_30d_txt": "0.0", "purchase_ratio_txt": "0.000000",
        "days_since_last_purchase_txt": "31.000000", "activity_trend_txt": "0.0",
        "brand_concentration_ratio_txt": "1.0", "brand_switch_count_30d_txt": "0",
        "visit_regularity_txt": "-1.0", "activity_ratio_15d_txt": "0.0", "n_events_7d_txt": "0", "price_volatility_txt": "0.0"
    },
    "Top 15%": {
        "n_events_30d_txt": "1", "active_days_30d_txt": "1", "n_purchase_30d_txt": "1",
        "purchase_ratio_txt": "0.000000", "days_since_last_event_txt": "17.657164",
        "days_since_last_purchase_txt": "31.00000", "brand_concentration_ratio_txt": "1.0",
        "brand_switch_count_30d_txt": "0", "total_spend_30d_txt": "0.0",
        "activity_ratio_15d_txt": "0.0", "n_events_7d_txt": "0",
        "visit_regularity_txt": "-1.0", "activity_trend_txt": "0.0", "price_volatility_txt": "0.0"
    },
    "Top 30%": {
        "n_events_30d_txt": "6",
        "active_days_30d_txt": "1",
        "n_purchase_30d_txt": "1",
        "purchase_ratio_txt": "0.05",
        "days_since_last_event_txt": "26.304306",
        "days_since_last_purchase_txt": "26.312245",
        "brand_concentration_ratio_txt": "1.0",
        "brand_switch_count_30d_txt": "0",
        "total_spend_30d_txt": "295.73",
        "activity_ratio_15d_txt": "0.0",
        "n_events_7d_txt": "0",
        "visit_regularity_txt": "0.00041",
        "activity_trend_txt": "0.0",
        "price_volatility_txt": "0.0"
    }
    # "Top 30%": {
    #    "n_events_30d_txt": "4", "active_days_30d_txt": "1", "n_purchase_30d_txt": "1",
    #     "purchase_ratio_txt": "0.000000", "days_since_last_event_txt": "20.731053",
    #     "days_since_last_purchase_txt": "31.00000", "brand_concentration_ratio_txt": "1.0",
    #     "brand_switch_count_30d_txt": "0", "total_spend_30d_txt": "0.0",
    #     "activity_ratio_15d_txt": "0.0", "n_events_7d_txt": "0",
    #     "visit_regularity_txt": "0.000193", "activity_trend_txt": "0.0", "price_volatility_txt": "0.0"
    # }
}

# [ìˆ˜ì •] load_preset: ê°’ë§Œ ì±„ìš°ê³  UI ë¦¬í”„ë ˆì‹œ (ì˜ˆì¸¡ ë¡œì§ X)
def load_preset(preset_name):
    if preset_name in PRESET_VALUES:
        for key, val in PRESET_VALUES[preset_name].items():
            st.session_state[key] = val
        st.rerun()

col_left, col_right = st.columns([3, 2], gap="large")

with col_left:
    # 1. íƒ­ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ CSS ì£¼ì…
    st.markdown("""
    <style>
        .stTabs [data-baseweb="tab-list"] {
            gap: 24px; 
            border-bottom: 2px solid #dd2e1f !important; 
            padding-bottom: 4px !important; 
        }
        .stTabs [data-baseweb="tab-highlight"] {
            background-color: transparent !important;
            height: 0px !important;
        }
        .stTabs [data-baseweb="tab"] {
            padding-top: 0px !important;
            padding-bottom: 0px !important;
            margin-bottom: 0px !important; 
            margin-top: 0px !important;
        }
        .stTabs [data-baseweb="tab"][aria-selected="true"] {
            color: #dd2e1f !important;
            font-weight: 900 !important;
            border-bottom: 6px solid #dd2e1f !important; 
        }
    </style>
    """, unsafe_allow_html=True)

    # 2. íƒ­ ìƒì„±
    tab_5, tab_15, tab_30 = st.tabs(["ğŸ”´ Top 5%", "ğŸŸ  Top 15%", "ğŸŸ¢ Top 30%"])

    with tab_5:
        if st.button("ì´ ë°ì´í„° ì ìš©í•˜ê¸°", key="btn_top5", use_container_width=True):
            load_preset("Top 5%")

    with tab_15:
        if st.button("ì´ ë°ì´í„° ì ìš©í•˜ê¸°", key="btn_top15", use_container_width=True):
            load_preset("Top 15%")

    with tab_30:
        if st.button("ì´ ë°ì´í„° ì ìš©í•˜ê¸°", key="btn_top30", use_container_width=True):
            load_preset("Top 30%")

    # [ìˆ˜ì •] ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜ í•´ê²° (with col_left ì•ˆìœ¼ë¡œ ì´ë™)
    st.markdown('<div style="border-bottom: 2px solid #dd2e1f; margin-bottom: 1rem; margin-top: 0.5rem;"></div>', unsafe_allow_html=True)

    with st.form("prediction_form"):
        st.markdown('<div class="section-header">ğŸ“Š í•µì‹¬ í™œë™ ì§€í‘œ</div>', unsafe_allow_html=True)
        c1, c2 = st.columns(2)
        with c1:
            active_days_30d, err_active_days_30d = input_int_placeholder("30ì¼ í™œë™ì¼ìˆ˜", key="active_days_30d_txt", min_v=0, max_v=30)
            n_events_30d, err_n_events_30d = input_int_placeholder("30ì¼ ì´ë²¤íŠ¸ ìˆ˜", key="n_events_30d_txt", min_v=0, max_v=1824)
            n_purchase_30d, err_n_purchase_30d = input_int_placeholder("ìµœê·¼ 30ì¼ êµ¬ë§¤ íšŸìˆ˜", key="n_purchase_30d_txt", min_v=0, max_v=512)
        with c2:
            days_since_last_event, err_days_since_last_event = input_float_placeholder("ë§ˆì§€ë§‰ í™œë™ (ì¼)", key="days_since_last_event_txt", min_v=0, max_v=31)
            days_since_last_purchase, err_days_since_last_purchase = input_float_placeholder("ë§ˆì§€ë§‰ êµ¬ë§¤ (ì¼)", key="days_since_last_purchase_txt", min_v=0, max_v=31)
            purchase_ratio, err_purchase_ratio = input_float_placeholder("êµ¬ë§¤ ì „í™˜ìœ¨ (0~1)", key="purchase_ratio_txt", min_v=0.0, max_v=1.0)
        st.markdown("</div>", unsafe_allow_html=True)

        with st.expander("ğŸ”§ ê³ ê¸‰ ë¶„ì„ ì§€í‘œ", expanded=False):
            st.markdown('<div class="section-header">ğŸ” í™œë™ ì¶”ì„¸</div>', unsafe_allow_html=True)
            activity_trend, err_activity_trend = input_float_placeholder("í™œë™ ì¶”ì„¸", key="activity_trend_txt", min_v=0.0, max_v=1.0)
            st.markdown("</div>", unsafe_allow_html=True)

            st.markdown('<div class="section-header">ğŸ·ï¸ ë¸Œëœë“œ íŒ¨í„´</div>', unsafe_allow_html=True)
            cc1, cc2 = st.columns(2)
            with cc1:
                brand_concentration_ratio, err_brand_concentration_ratio = input_float_placeholder("ë¸Œëœë“œ ì§‘ì¤‘ë„ (0~1)", key="brand_concentration_ratio_txt", min_v=0.0, max_v=1.0)
                brand_switch_count_30d, err_brand_switch_count_30d = input_int_placeholder("ë¸Œëœë“œ ì „í™˜ íšŸìˆ˜", key="brand_switch_count_30d_txt", min_v=0, max_v=616)
            with cc2:
                visit_regularity, err_visit_regularity = input_float_placeholder("ë°©ë¬¸ ê·œì¹™ì„± (-1~21)", key="visit_regularity_txt", min_v=-1.0, max_v=21.0)
                activity_ratio_15d, err_activity_ratio_15d = input_float_placeholder("15ì¼ í™œë™ ë¹„ì¤‘ (0~1)", key="activity_ratio_15d_txt", min_v=0, max_v=1.0)
            n_events_7d, err_n_events_7d = input_int_placeholder("7ì¼ ì´ë²¤íŠ¸ ìˆ˜", key="n_events_7d_txt", min_v=0, max_v=311)
            price_volatility, err_price_volatility = input_float_placeholder("ê°€ê²© ë³€ë™ì„± (0~553)", key="price_volatility_txt", min_v=0, max_v=553.0)
            st.markdown("</div>", unsafe_allow_html=True)

        st.markdown("<br>", unsafe_allow_html=True)
        # [ì¤‘ìš”] submit ë²„íŠ¼ ë³€ìˆ˜ í• ë‹¹
        submit = st.form_submit_button("ì˜ˆì¸¡í•˜ê¸°", use_container_width=True)


# ì˜ˆì¸¡ ë° ê²°ê³¼

def collect_errors(*errs):
    return [e for e in errs if e is not None]

# ì´ˆê¸°í™”
radar_values = [0.0, 0.0, 0.0, 0.0, 0.0]
prob = 0.0
latency_ms = 0.0
risk_level = "Ready"
risk_color = "#e9ecef"
risk_icon = "âšª"
risk_bg = "#f8f9fa"
hit_k = None
pct_label = ""
is_analyzed = False
user_inputs = {}

# [í•µì‹¬] submit(ì˜ˆì¸¡í•˜ê¸° ë²„íŠ¼)ì„ ëˆŒë €ì„ ë•Œë§Œ ì‹¤í–‰
if submit:
    # 1. ì—ëŸ¬ ì²´í¬
    errors = collect_errors(
        err_n_purchase_30d, err_days_since_last_event, err_n_events_30d, err_active_days_30d, err_activity_trend,
        # err_total_spend_30d, # ì£¼ì„ ì²˜ë¦¬ë¨
        err_days_since_last_purchase, err_purchase_ratio,
        err_brand_concentration_ratio, err_brand_switch_count_30d, err_visit_regularity, 
        err_activity_ratio_15d, err_n_events_7d, err_price_volatility
    )

    if errors:
        st.error("ì…ë ¥ê°’ì„ í™•ì¸í•´ì£¼ì„¸ìš”: " + ", ".join(errors))
    else:
        # 2. [ì¤‘ìš”] UIì—ì„œ ì£¼ì„ ì²˜ë¦¬í•œ ë³€ìˆ˜ëŠ” ì—¬ê¸°ì„œ ê¸°ë³¸ê°’ì„ 0.0ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜ì•¼ ì—ëŸ¬ê°€ ì•ˆ ë‚©ë‹ˆë‹¤.
        total_spend_30d = 0.0 

        # 3. ì…ë ¥ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ë“¤ì—¬ì“°ê¸° ì •ë ¬ ì™„ë£Œ)
        user_inputs = {
            "n_events_30d": int(n_events_30d), 
            "active_days_30d": int(active_days_30d), 
            "n_purchase_30d": int(n_purchase_30d),
            "purchase_ratio": float(purchase_ratio), 
            "days_since_last_event": float(days_since_last_event),
            "days_since_last_purchase": float(days_since_last_purchase), 
            "brand_concentration_ratio": float(brand_concentration_ratio),
            "brand_switch_count_30d": int(brand_switch_count_30d), 
            "total_spend_30d": float(total_spend_30d), # ìœ„ì—ì„œ 0.0ìœ¼ë¡œ ì •ì˜í•¨
            "activity_ratio_15d": float(activity_ratio_15d), 
            "price_volatility": float(price_volatility),
            "n_events_7d": int(n_events_7d), 
            "visit_regularity": float(visit_regularity), 
            "activity_trend": float(activity_trend),
        }

        x_df = pd.DataFrame([[user_inputs[c] for c in FEATURE_ORDER]], columns=FEATURE_ORDER)

        with st.spinner("âš¡ AI ëª¨ë¸ ë¶„ì„ ì¤‘..."):
            t0 = time.time()
            if scaler is not None:
                x_scaled = scaler.transform(x_df)
                x_in = pd.DataFrame(x_scaled, columns=FEATURE_ORDER)
            else:
                arr = []
                for col in FEATURE_ORDER:
                    mean_v = float(STATS[col]["mean"]); std_v = float(STATS[col]["std"])
                    raw = float(user_inputs[col])
                    arr.append(0.0 if std_v == 0 else (raw - mean_v) / std_v)
                x_in = pd.DataFrame([arr], columns=FEATURE_ORDER)

            prob = predict_prob(model, x_in)
            latency_ms = (time.time() - t0) * 1000
            
            risk_level, risk_color, risk_icon, risk_bg, hit_k = risk_from_topk(prob, topk_cutoffs)
            pct_label = percentile_label(prob, pcts)
            
            val_activity_freq = 0.0
            if user_inputs["n_events_30d"] > 0:
                val_activity_freq = 1.0 - min(user_inputs["n_events_30d"] / 1000, 1.0)

            val_spend_score = 0.0
            if user_inputs["total_spend_30d"] > 0:
                val_spend_score = 1.0 - min(user_inputs["total_spend_30d"] / 1_000_000, 1.0)

            val_ratio_score = 0.0
            if user_inputs["purchase_ratio"] > 0:
                val_ratio_score = 1.0 - float(user_inputs["purchase_ratio"])
            
            radar_values = [
                min(user_inputs["days_since_last_event"] / 60, 1.0),
                val_activity_freq,
                val_spend_score,
                val_ratio_score,
                min(abs(user_inputs["activity_trend"]) / 10, 1.0) if user_inputs["activity_trend"] < 0 else 0
            ]
            
            is_analyzed = True

# ì‹œê°í™” ë¶€ë¶„ 
categories = ["ìµœê·¼ì„±", "í™œë™ë¹ˆë„", "ì „í™˜ìœ¨", "í™œë™ì¶”ì„¸"]
# ë ˆì´ë” ì°¨íŠ¸ ê°’ë„ ì°¨ì›ì— ë§ì¶° ì¡°ì • (êµ¬ë§¤ì•¡ ì œì™¸ 4ê°œë¡œ ì¤„ì´ì‹  ê²½ìš°)
radar_values_4dim = [
    radar_values[0], # ìµœê·¼ì„±
    radar_values[1], # í™œë™ë¹ˆë„
    radar_values[3], # ì „í™˜ìœ¨ (êµ¬ë§¤ì•¡ ì¸ë±ìŠ¤ 2 ê±´ë„ˆëœ€)
    radar_values[4]  # í™œë™ì¶”ì„¸
]

fig_radar = go.Figure()
fig_radar.add_trace(go.Scatterpolar(
    r=radar_values_4dim, 
    theta=categories, 
    fill='toself',
    fillcolor=f'rgba({int(risk_color[1:3], 16)}, {int(risk_color[3:5], 16)}, {int(risk_color[5:7], 16)}, 0.25)' if is_analyzed else 'rgba(200,200,200,0.2)',
    line=dict(color=risk_color if is_analyzed else '#ccc', width=3),
    marker=dict(size=10, color=risk_color if is_analyzed else '#ccc'),
    hovertemplate='%{theta}: %{r:.1%}<extra></extra>', name='ìœ„í—˜ë„'
))

# [ìˆ˜ì •] ë ˆì´ë” ì°¨íŠ¸ ë†’ì´ ì¶•ì†Œ ë°˜ì˜ (height=220)
fig_radar.update_layout(
    polar=dict(
        radialaxis=dict(visible=True, range=[0, 1], tickformat='.0%', gridcolor='#e8e8e8', tickfont=dict(size=10)),
        angularaxis=dict(gridcolor='#e8e8e8', tickfont=dict(size=11, color='#333'))
    ),
    showlegend=False, 
    height=220,  # <-- ë†’ì´ 220ìœ¼ë¡œ ì¶•ì†Œ
    margin=dict(l=35, r=35, t=20, b=20),
    paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)',
)

with col_right:
    # margin: ìƒë‹¨0 ì¢Œìš°0 í•˜ë‹¨6px (ë‹¨ìœ„ë¥¼ pxë‚˜ rem ì¤‘ ì›í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”)
    st.markdown('<div class="section-header" style="padding-bottom: 0px;margin: 0.95rem 0px 16px;">ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼</div>', unsafe_allow_html=True)
    latency_display = f"âš¡ {latency_ms:.2f} ms" if is_analyzed else "Ready"
    latency_txt_color = "#28a745" if is_analyzed else "#ccc"
    sub = []
    if hit_k is not None: sub.append(f"Top {hit_k}%")
    if pct_label: sub.append(pct_label)
    sub_txt = " | ".join(sub) if sub else "ë°ì´í„°ë¥¼ ì…ë ¥í•˜ê³  ì˜ˆì¸¡ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”"

    display_prob = (prob - 0.01) * 100 if is_analyzed else 0.0
    if display_prob < 0: display_prob = 0.0

    st.markdown(f"""
        <div class="result-wrap" style="background:{risk_bg};">
            <div class="result-card" style="background: transparent; box-shadow:none; margin:0; padding: 0.2rem;">
                <div style="text-align: center;">
                    <div style="font-size: 0.8rem; color: #666; margin-bottom: 0.2rem;">{sub_txt}</div>
                    <div style="color: {risk_color if is_analyzed else '#ccc'}; font-size: 2.4rem; font-weight: 800; line-height: 1.1; margin: 0;">
                        {display_prob:.1f}%
                    </div>
                    <div style="font-size: 0.85rem; color: #888; margin-bottom: 0.5rem;">ì´íƒˆ í™•ë¥ </div>
                    <div class="risk-badge" style="background: {risk_color}; color: {'white' if is_analyzed else '#666'}; padding: 0.3rem 1.2rem; font-size: 0.9rem; margin-top: 0;">
                        {risk_icon} {risk_level}
                    </div>
                    <div style="margin-top: 0.4rem; font-size: 0.75rem; color: {latency_txt_color}; font-weight: 600;">{latency_display}</div>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    t1, t2 = st.columns([2,1])
    with t1:
        # [ìˆ˜ì •] style="margin-top: 5px; margin-bottom: 5px;" ì¶”ê°€
        st.markdown("""
            <div class="frame-head" style="margin-top: 5px; margin-bottom: 5px;">
                <div class="frame-title">ğŸ“Š ìœ„í—˜ ìš”ì¸ ë¶„ì„</div>
            </div>
            <div class="frame-line" style="margin-top: 5px; margin-bottom: 30px;"></div>
            """, unsafe_allow_html=True)
        st.plotly_chart(fig_radar, use_container_width=True)

    with t2:
        # [ìˆ˜ì •] style="margin-top: 5px; margin-bottom: 5px;" ì¶”ê°€
        st.markdown("""
            <div class="frame-head" style="margin-top: 5px; margin-bottom: 5px;">
                <div class="frame-title">ğŸ“ˆ í•µì‹¬ ì§€í‘œ</div>
            </div>
            <div class="frame-line" style="margin-top: 5px; margin-bottom: 20px;"></div>
            """, unsafe_allow_html=True)
        st.markdown('<div class="kpi-pane">', unsafe_allow_html=True)
        
        # [ìˆ˜ì •] user_inputs ì•ˆì „í•˜ê²Œ ì ‘ê·¼í•˜ì—¬ KPI í‘œì‹œ
        if is_analyzed:
            val_days = f"{int(user_inputs['days_since_last_event'])}ì¼"
            val_spend = f"{user_inputs['total_spend_30d']/10000:.0f}ë§Œì›"
            val_ratio = f"{user_inputs['purchase_ratio']*100:.1f}%"
        else:
            val_days = "-"
            val_spend = "-"
            val_ratio = "-"

        st.markdown(f"""
            <div class="kpi-wrap">
                <div class="stat-card-small"><div class="stat-label">ìµœê·¼ í™œë™</div><div class="stat-value">{val_days}</div></div>
                <div class="stat-card-small"><div class="stat-label">ì „í™˜ìœ¨</div><div class="stat-value">{val_ratio}</div></div>
            </div>
            """, unsafe_allow_html=True)
        st.markdown("</div>", unsafe_allow_html=True)