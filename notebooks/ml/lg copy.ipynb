{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 현재 파일 위치 기준으로 위로 올라가며 \"app\" 폴더를 찾는다\n",
    "p = Path.cwd().resolve()\n",
    "for _ in range(6):  # 최대 6단계 위까지 탐색\n",
    "    if (p / \"app\").exists() and (p / \"models\").exists():\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(\"✅ project root added to sys.path:\", p)\n",
    "        break\n",
    "    p = p.parent\n",
    "else:\n",
    "    raise RuntimeError(\"❌ 프로젝트 루트를 찾지 못했어요. app/ 와 models/ 가 있는 폴더에서 실행해야 합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6740a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parquet files\n",
      "rows: 813540 train/val/test: 574092 137615 101833\n",
      "n_features: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=0.0. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_val_score: 0.2624901150924944\n",
      "best_val_pr_auc: 0.911759992868709\n",
      "best_val_precision_k: 0.9401206307681128\n",
      "best_val_recall_k: 0.11169533084680204\n",
      "best_val_lift_k: 1.1169938924847513\n",
      "best_lr_params: {\n",
      "  \"solver\": \"lbfgs\",\n",
      "  \"penalty\": \"l2\",\n",
      "  \"C\": 0.003,\n",
      "  \"max_iter\": 8000,\n",
      "  \"class_weight\": \"balanced\",\n",
      "  \"random_state\": 42\n",
      "}\n",
      "PR-AUC: 0.9302892269175418\n",
      "saved keys: ['model', 'scaler', 'config', 'eval_dir', 'version_dir', 'figure_pr_curve', 'figure_confusion_matrix_top5', 'figure_confusion_matrix_top10', 'figure_confusion_matrix_top15', 'figure_confusion_matrix_top30']\n",
      "model -> /Users/jy/project_2nd/SKN23-2nd-3Team/models/ml/mllg/tuned_on_val/model.pkl\n",
      "scaler -> /Users/jy/project_2nd/SKN23-2nd-3Team/models/preprocessing/mllg/tuned_on_val/scaler.pkl\n",
      "config -> /Users/jy/project_2nd/SKN23-2nd-3Team/models/configs/mllg/tuned_on_val/config.json\n",
      "eval_dir -> /Users/jy/project_2nd/SKN23-2nd-3Team/models/eval/mlmllg\n",
      "version_dir -> tuned_on_val\n",
      "figure_pr_curve -> /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/mllg/tuned_on_val/pr_curve.png\n",
      "figure_confusion_matrix_top5 -> /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/mllg/tuned_on_val/confusion_matrix_top5.png\n",
      "figure_confusion_matrix_top10 -> /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/mllg/tuned_on_val/confusion_matrix_top10.png\n",
      "figure_confusion_matrix_top15 -> /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/mllg/tuned_on_val/confusion_matrix_top15.png\n",
      "figure_confusion_matrix_top30 -> /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/mllg/tuned_on_val/confusion_matrix_top30.png\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, average_precision_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "here = Path.cwd().resolve()\n",
    "project_root = next(\n",
    "    (\n",
    "        p\n",
    "        for p in [here, *here.parents]\n",
    "        if (p / \"app\").is_dir() and (p / \"models\").is_dir() and (p / \"data\").is_dir()\n",
    "    ),\n",
    "    None,\n",
    ")\n",
    "if project_root is None:\n",
    "    raise FileNotFoundError(f\"프로젝트 루트를 못 찾았어. 현재 위치={here}\")\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "for k in list(sys.modules.keys()):\n",
    "    if k == \"app\" or k.startswith(\"app.\"):\n",
    "        del sys.modules[k]\n",
    "\n",
    "from app.utils.paths import DEFAULT_PATHS as P, ensure_runtime_dirs\n",
    "from app.utils.metrics import evaluate_churn_metrics\n",
    "from app.utils.save import save_model_and_artifacts\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "ensure_runtime_dirs()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_figure(y_true, y_pred, title: str, labels=(\"non_m2\", \"m2\")):\n",
    "    y_true_arr = np.asarray(y_true, dtype=int).reshape(-1)\n",
    "    y_pred_arr = np.asarray(y_pred, dtype=int).reshape(-1)\n",
    "    cm = confusion_matrix(y_true_arr, y_pred_arr)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\", aspect=\"equal\", cmap=\"Blues\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(list(labels))\n",
    "    ax.set_yticklabels(list(labels))\n",
    "\n",
    "    thresh = float(cm.max()) / 2.0 if cm.size else 0.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(\n",
    "                j,\n",
    "                i,\n",
    "                str(cm[i, j]),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\" if float(cm[i, j]) > thresh else \"black\",\n",
    "                fontsize=12,\n",
    "            )\n",
    "\n",
    "    ax.set_xlim(-0.5, cm.shape[1] - 0.5)\n",
    "    ax.set_ylim(cm.shape[0] - 0.5, -0.5)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def topk_threshold(y_prob: np.ndarray, k_pct: int) -> float:\n",
    "    prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    order = np.argsort(-prob)\n",
    "    n_sel = int(np.floor(len(prob) * (float(k_pct) / 100.0)))\n",
    "    n_sel = max(n_sel, 1)\n",
    "    return float(prob[order[n_sel - 1]])\n",
    "\n",
    "\n",
    "def plot_confusion_topk(y_true, y_prob, k_pct: int, labels=(\"non_m2\", \"m2\")):\n",
    "    thr = topk_threshold(np.asarray(y_prob, dtype=float), int(k_pct))\n",
    "    y_pred = (np.asarray(y_prob, dtype=float) >= thr).astype(int)\n",
    "    return plot_confusion_matrix_figure(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        title=f\"Confusion Matrix (Top {int(k_pct)}%, thr={thr:.5f})\",\n",
    "        labels=labels,\n",
    "    )\n",
    "\n",
    "\n",
    "def topk_precision_recall_lift(y_true: np.ndarray, y_prob: np.ndarray, k_pct: int = 5):\n",
    "    y_true = np.asarray(y_true, dtype=int).reshape(-1)\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "\n",
    "    thr = topk_threshold(y_prob, int(k_pct))\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    if (y_pred == 1).any():\n",
    "        precision_k = float(y_true[y_pred == 1].mean())\n",
    "        selected_pos = float(y_true[y_pred == 1].sum())\n",
    "    else:\n",
    "        precision_k = 0.0\n",
    "        selected_pos = 0.0\n",
    "\n",
    "    total_pos = float(y_true.sum())\n",
    "    recall_k = float(selected_pos / (total_pos + 1e-12))\n",
    "\n",
    "    base_rate = float(y_true.mean())\n",
    "    lift_k = float(precision_k / base_rate) if base_rate > 0 else 0.0\n",
    "\n",
    "    return precision_k, recall_k, lift_k, float(thr)\n",
    "\n",
    "\n",
    "def tune_lr_on_val_topk(\n",
    "    X_train_s,\n",
    "    y_train,\n",
    "    X_val_s,\n",
    "    y_val,\n",
    "    seed=42,\n",
    "    k_pct=10,\n",
    "    alpha=0.85,\n",
    "):\n",
    "    C_list = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10.0, 30.0]\n",
    "    candidates = []\n",
    "\n",
    "    for C in C_list:\n",
    "        candidates.append({\"solver\": \"lbfgs\", \"penalty\": \"l2\", \"C\": float(C), \"l1_ratio\": None})\n",
    "\n",
    "    for C in C_list:\n",
    "        candidates.append({\"solver\": \"saga\", \"penalty\": \"l1\", \"C\": float(C), \"l1_ratio\": None})\n",
    "\n",
    "    for C in C_list:\n",
    "        for l1r in [0.15, 0.3, 0.5, 0.7, 0.85]:\n",
    "            candidates.append(\n",
    "                {\"solver\": \"saga\", \"penalty\": \"elasticnet\", \"C\": float(C), \"l1_ratio\": float(l1r)}\n",
    "            )\n",
    "\n",
    "    best = {\n",
    "        \"score\": -1.0,\n",
    "        \"params\": None,\n",
    "        \"val_precision\": None,\n",
    "        \"val_recall\": None,\n",
    "        \"val_lift\": None,\n",
    "        \"val_thr\": None,\n",
    "        \"val_pr_auc\": None,\n",
    "        \"k_pct\": int(k_pct),\n",
    "        \"alpha\": float(alpha),\n",
    "    }\n",
    "\n",
    "    y_val_int = np.asarray(y_val, dtype=int).reshape(-1)\n",
    "\n",
    "    for cand in candidates:\n",
    "        params = dict(\n",
    "            solver=cand[\"solver\"],\n",
    "            penalty=cand[\"penalty\"],\n",
    "            C=cand[\"C\"],\n",
    "            max_iter=8000,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=seed,\n",
    "        )\n",
    "        if cand[\"penalty\"] == \"elasticnet\":\n",
    "            params[\"l1_ratio\"] = cand[\"l1_ratio\"]\n",
    "        if cand[\"solver\"] == \"saga\":\n",
    "            params[\"n_jobs\"] = -1\n",
    "\n",
    "        model = LogisticRegression(**params)\n",
    "        model.fit(X_train_s, y_train)\n",
    "\n",
    "        val_prob = model.predict_proba(X_val_s)[:, 1].astype(float)\n",
    "        prec_k, rec_k, lift_k, thr = topk_precision_recall_lift(y_val_int, val_prob, k_pct=int(k_pct))\n",
    "        pr_auc = float(average_precision_score(y_val_int, val_prob))\n",
    "\n",
    "        score = float(alpha * rec_k + (1.0 - alpha) * lift_k)\n",
    "\n",
    "        if score > best[\"score\"]:\n",
    "            best.update(\n",
    "                {\n",
    "                    \"score\": score,\n",
    "                    \"params\": params,\n",
    "                    \"val_precision\": prec_k,\n",
    "                    \"val_recall\": rec_k,\n",
    "                    \"val_lift\": lift_k,\n",
    "                    \"val_thr\": thr,\n",
    "                    \"val_pr_auc\": pr_auc,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "print(\"Load parquet files\")\n",
    "\n",
    "anchors = pd.read_parquet(P.parquet_path(\"anchors\"))\n",
    "features = pd.read_parquet(P.parquet_path(\"features_ml_clean\"))\n",
    "labels = pd.read_parquet(P.parquet_path(\"labels\"))\n",
    "\n",
    "for df in (anchors, features, labels):\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "\n",
    "if \"split\" in anchors.columns:\n",
    "    anchors = anchors.drop(columns=[\"split\"])\n",
    "\n",
    "if \"split\" not in labels.columns:\n",
    "    raise KeyError(f\"labels.parquet에 split 컬럼이 없습니다. labels columns head: {list(labels.columns)[:50]}\")\n",
    "\n",
    "data = anchors.merge(features, on=[\"user_id\", \"anchor_time\"], how=\"inner\")\n",
    "data = data.merge(labels[[\"user_id\", \"anchor_time\", \"label\", \"split\"]], on=[\"user_id\", \"anchor_time\"], how=\"inner\")\n",
    "\n",
    "data[\"target\"] = data[\"label\"].astype(str).eq(\"m2\").astype(int)\n",
    "split_col = data[\"split\"].astype(str)\n",
    "\n",
    "feature_cols = [c for c in features.columns if c not in (\"user_id\", \"anchor_time\")]\n",
    "X_all = data.loc[:, feature_cols].fillna(0.0)\n",
    "y_all = data[\"target\"].to_numpy(dtype=int)\n",
    "\n",
    "idx_train = split_col.eq(\"train\").to_numpy()\n",
    "idx_val = split_col.eq(\"val\").to_numpy()\n",
    "idx_test = split_col.eq(\"test\").to_numpy()\n",
    "\n",
    "X_train = X_all.loc[idx_train].to_numpy(dtype=float)\n",
    "y_train = y_all[idx_train]\n",
    "X_val = X_all.loc[idx_val].to_numpy(dtype=float)\n",
    "y_val = y_all[idx_val]\n",
    "X_test = X_all.loc[idx_test].to_numpy(dtype=float)\n",
    "y_test = y_all[idx_test]\n",
    "\n",
    "print(\"rows:\", len(data), \"train/val/test:\", int(idx_train.sum()), int(idx_val.sum()), int(idx_test.sum()))\n",
    "print(\"n_features:\", int(X_train.shape[1]))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s = scaler.transform(X_val)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "k_pct_for_selection = 10\n",
    "alpha_for_selection = 0.85\n",
    "\n",
    "tuned = tune_lr_on_val_topk(\n",
    "    X_train_s,\n",
    "    y_train,\n",
    "    X_val_s,\n",
    "    y_val,\n",
    "    seed=42,\n",
    "    k_pct=k_pct_for_selection,\n",
    "    alpha=alpha_for_selection,\n",
    ")\n",
    "\n",
    "print(\"best_val_score:\", float(tuned[\"score\"]))\n",
    "print(\"best_val_pr_auc:\", float(tuned[\"val_pr_auc\"]))\n",
    "print(\"best_val_precision_k:\", float(tuned[\"val_precision\"]))\n",
    "print(\"best_val_recall_k:\", float(tuned[\"val_recall\"]))\n",
    "print(\"best_val_lift_k:\", float(tuned[\"val_lift\"]))\n",
    "print(\"best_lr_params:\", json.dumps(tuned[\"params\"], ensure_ascii=False, indent=2))\n",
    "\n",
    "X_tv_s = np.vstack([X_train_s, X_val_s])\n",
    "y_tv = np.concatenate([np.asarray(y_train, dtype=int), np.asarray(y_val, dtype=int)])\n",
    "\n",
    "final_params = tuned[\"params\"].copy()\n",
    "model = LogisticRegression(**final_params)\n",
    "model.fit(X_tv_s, y_tv)\n",
    "\n",
    "y_prob = model.predict_proba(X_test_s)[:, 1].astype(float).reshape(-1)\n",
    "y_true = np.asarray(y_test, dtype=int).reshape(-1)\n",
    "\n",
    "metrics = evaluate_churn_metrics(y_true, y_prob)\n",
    "metrics[\"val_selection_k_pct\"] = int(k_pct_for_selection)\n",
    "metrics[\"val_selection_alpha\"] = float(alpha_for_selection)\n",
    "metrics[\"best_val_score\"] = float(tuned[\"score\"])\n",
    "metrics[\"best_val_precision_k\"] = float(tuned[\"val_precision\"])\n",
    "metrics[\"best_val_recall_k\"] = float(tuned[\"val_recall\"])\n",
    "metrics[\"best_val_lift_k\"] = float(tuned[\"val_lift\"])\n",
    "metrics[\"best_val_pr_auc\"] = float(tuned[\"val_pr_auc\"])\n",
    "\n",
    "print(\"PR-AUC:\", float(metrics.get(\"PR-AUC (Average Precision)\", 0.0)))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "pr_auc_val = metrics.get(\"PR-AUC (Average Precision)\")\n",
    "pr_auc_val = float(average_precision_score(y_true, y_prob)) if pr_auc_val is None else float(pr_auc_val)\n",
    "\n",
    "fig_pr, ax_pr = plt.subplots(figsize=(6, 5))\n",
    "ax_pr.plot(recall, precision, lw=2, label=f\"PR-AUC={pr_auc_val:.5f}\")\n",
    "ax_pr.set_xlabel(\"Recall\")\n",
    "ax_pr.set_ylabel(\"Precision\")\n",
    "ax_pr.set_title(\"Precision-Recall Curve\")\n",
    "ax_pr.grid(alpha=0.3)\n",
    "ax_pr.legend()\n",
    "fig_pr.tight_layout()\n",
    "\n",
    "figures = {\"pr_curve\": fig_pr}\n",
    "for k_pct in (5, 10, 15, 30):\n",
    "    figures[f\"confusion_matrix_top{k_pct}\"] = plot_confusion_topk(\n",
    "        y_true=y_true,\n",
    "        y_prob=y_prob,\n",
    "        k_pct=int(k_pct),\n",
    "        labels=(\"non_m2\", \"m2\"),\n",
    "    )\n",
    "\n",
    "saved = save_model_and_artifacts(\n",
    "    model=model,\n",
    "    model_name=\"mllg\",\n",
    "    model_type=\"ml\",\n",
    "    model_id=\"ml__mllg\",\n",
    "    split=\"test\",\n",
    "    metrics=metrics,\n",
    "    y_true=y_true,\n",
    "    y_prob=y_prob,\n",
    "    version=\"tuned_on_val\",\n",
    "    scaler=scaler,\n",
    "    figures=figures,\n",
    "    config={\n",
    "        \"model_name\": \"mllg\",\n",
    "        \"model_type\": \"ml\",\n",
    "        \"version\": \"tuned_on_val\",\n",
    "        \"feature_source\": \"features_ml_clean.parquet\",\n",
    "        \"selection_rule\": f\"val score = {alpha_for_selection}*Recall@Top{k_pct_for_selection}% + {1.0-alpha_for_selection}*Lift@Top{k_pct_for_selection}%\",\n",
    "        \"best_lr_params\": final_params,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"saved keys:\", list(saved.keys()))\n",
    "for k, v in saved.items():\n",
    "    print(k, \"->\", v)\n",
    "\n",
    "plt.close(fig_pr)\n",
    "for k_pct in (5, 10, 15, 30):\n",
    "    plt.close(figures[f\"confusion_matrix_top{k_pct}\"])\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab9d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
