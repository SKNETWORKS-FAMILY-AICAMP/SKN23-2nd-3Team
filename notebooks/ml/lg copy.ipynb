{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e444f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/churn_venv/lib/python3.14/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4842"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, confusion_matrix\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "PROJECT_ROOT = Path(\"/Users/jy/project_2nd/SKN23-2nd-3Team\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from app.utils.save import save_model_and_artifacts\n",
    "from app.utils.paths import PATHS\n",
    "\n",
    "try:\n",
    "    from app.utils.plotting import configure_matplotlib_korean\n",
    "    configure_matplotlib_korean()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "def to_py(obj):\n",
    "    if isinstance(obj, (np.integer,)): return int(obj)\n",
    "    if isinstance(obj, (np.floating,)): return float(obj)\n",
    "    if isinstance(obj, (np.bool_,)): return bool(obj)\n",
    "    return obj\n",
    "\n",
    "def dict_to_py(d: dict) -> dict:\n",
    "    return {str(k): to_py(v) for k, v in d.items()}\n",
    "\n",
    "def write_streamlit_score_percentiles(model_name: str, payload: dict) -> str:\n",
    "    out = PROJECT_ROOT / \"models\" / \"metrics\" / f\"{model_name}_score_percentiles.json\"\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    return str(out)\n",
    "\n",
    "def score_percentiles_payload(model_id: str, split: str, y_prob, pcts=(1, 5, 10, 20, 30, 50)):\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    percentiles = [{\"pct\": int(p), \"score\": float(np.quantile(y_prob, 1.0 - p / 100.0))} for p in pcts]\n",
    "    return {\"model_id\": model_id, \"split\": split, \"percentiles\": percentiles}\n",
    "\n",
    "def build_ranking_metrics(y_true, y_prob, k_list=(5, 10, 15, 30)):\n",
    "    y_true = np.asarray(y_true).astype(int).reshape(-1)\n",
    "    y_prob = np.asarray(y_prob).astype(float).reshape(-1)\n",
    "\n",
    "    pr_auc = float(average_precision_score(y_true, y_prob))\n",
    "\n",
    "    df_rank = pd.DataFrame({\"y\": y_true, \"score\": y_prob}).sort_values(\"score\", ascending=False)\n",
    "    base_rate = float(df_rank[\"y\"].mean())\n",
    "    total_pos = float(df_rank[\"y\"].sum())\n",
    "    n_total = int(len(df_rank))\n",
    "\n",
    "    ranking = []\n",
    "    for k in k_list:\n",
    "        n_sel = max(int(np.floor(n_total * k / 100)), 1)\n",
    "        selected = df_rank.iloc[:n_sel]\n",
    "\n",
    "        precision_k = float(selected[\"y\"].mean())\n",
    "        recall_k = float(selected[\"y\"].sum() / (total_pos + 1e-12))\n",
    "        lift_k = float(precision_k / base_rate) if base_rate > 0 else 0.0\n",
    "\n",
    "        ranking.append({\n",
    "            \"Top_K\": f\"{k}%\",\n",
    "            \"n_selected\": int(n_sel),\n",
    "            \"Precision\": precision_k,\n",
    "            \"Recall\": recall_k,\n",
    "            \"Lift\": lift_k,\n",
    "        })\n",
    "\n",
    "    def _get(k_pct: int):\n",
    "        target = f\"{k_pct}%\"\n",
    "        for row in ranking:\n",
    "            if row[\"Top_K\"] == target:\n",
    "                return row\n",
    "        return {\"Recall\": 0.0, \"Lift\": 0.0}\n",
    "\n",
    "    r5, r10, r30 = _get(5), _get(10), _get(30)\n",
    "    selection_score = (\n",
    "        0.55 * pr_auc\n",
    "        + 0.20 * float(r10[\"Recall\"])\n",
    "        + 0.15 * float(r30[\"Recall\"])\n",
    "        + 0.05 * float(r5[\"Recall\"])\n",
    "        + 0.03 * float(r10[\"Lift\"])\n",
    "        + 0.02 * float(r5[\"Lift\"])\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"PR-AUC (Average Precision)\": pr_auc,\n",
    "        \"base_rate\": base_rate,\n",
    "        \"n_total\": n_total,\n",
    "        \"ranking\": ranking,\n",
    "        \"score_for_selection\": float(selection_score),\n",
    "    }\n",
    "\n",
    "def threshold_topk(y_prob, k_pct: int) -> float:\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    order = np.argsort(-y_prob)\n",
    "    n_sel = max(int(np.floor(len(y_prob) * k_pct / 100)), 1)\n",
    "    return float(y_prob[order[n_sel - 1]])\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, labels=(\"비이탈(m1)\", \"이탈(m2)\"), cmap=\"Blues\"):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(cm, cmap=cmap, interpolation=\"nearest\", aspect=\"equal\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted (예측값)\")\n",
    "    ax.set_ylabel(\"Actual (실제값)\")\n",
    "\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    thresh = cm.max() / 2.0 if cm.size else 0.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(\n",
    "                j, i, f\"{cm[i, j]}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "            )\n",
    "\n",
    "    ax.set_xlim(-0.5, cm.shape[1] - 0.5)\n",
    "    ax.set_ylim(cm.shape[0] - 0.5, -0.5)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def make_figures(test_true, test_prob, k_list=(5, 10, 15, 30), cmap=\"Blues\"):\n",
    "    test_true = np.asarray(test_true).astype(int).reshape(-1)\n",
    "    test_prob = np.asarray(test_prob).astype(float).reshape(-1)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(test_true, test_prob)\n",
    "    pr_auc_val = float(average_precision_score(test_true, test_prob))\n",
    "\n",
    "    if len(recall) > 0 and recall[-1] == 0:\n",
    "        precision, recall = precision[:-1], recall[:-1]\n",
    "\n",
    "    fig_pr, ax_pr = plt.subplots(figsize=(6, 5))\n",
    "    ax_pr.plot(recall, precision, lw=2, label=f\"PR-AUC = {pr_auc_val:.5f}\")\n",
    "\n",
    "    base = float(np.mean(test_true))\n",
    "    ax_pr.hlines(base, 0, 1, linestyles=\"--\", label=f\"baseline={base:.3f}\")\n",
    "\n",
    "    ax_pr.set_xlabel(\"Recall\")\n",
    "    ax_pr.set_ylabel(\"Precision\")\n",
    "    ax_pr.set_title(\"Precision-Recall Curve\")\n",
    "    ax_pr.legend()\n",
    "    ax_pr.grid(alpha=0.3)\n",
    "    fig_pr.tight_layout()\n",
    "\n",
    "    figures = {\"pr_curve\": fig_pr}\n",
    "    for k in k_list:\n",
    "        thr = threshold_topk(test_prob, k)\n",
    "        y_pred_k = (test_prob >= thr).astype(int)\n",
    "        figures[f\"confusion_matrix_top{k}\"] = plot_confusion_matrix(\n",
    "            test_true, y_pred_k,\n",
    "            title=f\"Confusion Matrix (Top {k}%, thr={thr:.5f})\",\n",
    "            cmap=cmap,\n",
    "        )\n",
    "    return figures\n",
    "\n",
    "def tune_lg(X_train, y_train, X_val, y_val, n_trials=30, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    space = {\n",
    "        \"C\": [0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10.0],\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "    }\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_params = None\n",
    "    history = []\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "        params = {k: rng.choice(v) for k, v in space.items()}\n",
    "        params = {\n",
    "            \"C\": float(params[\"C\"]),\n",
    "            \"penalty\": str(params[\"penalty\"]),\n",
    "            \"class_weight\": (None if params[\"class_weight\"] is None else str(params[\"class_weight\"])),\n",
    "        }\n",
    "\n",
    "        model = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=2000,\n",
    "            random_state=42,\n",
    "            **params,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        val_prob = model.predict_proba(X_val)[:, 1]\n",
    "        val_pr_auc = float(average_precision_score(y_val, val_prob))\n",
    "\n",
    "        history.append({\"val_pr_auc\": val_pr_auc, \"params\": dict(params)})\n",
    "        if val_pr_auc > best_val:\n",
    "            best_val = val_pr_auc\n",
    "            best_params = dict(params)\n",
    "\n",
    "    return {\"val_pr_auc\": float(best_val), \"params\": best_params, \"history\": history}\n",
    "\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "features = pd.read_parquet(DATA_DIR / \"features_ml_clean.parquet\")\n",
    "labels = pd.read_parquet(DATA_DIR / \"labels.parquet\")\n",
    "\n",
    "features[\"user_id\"] = features[\"user_id\"].astype(str)\n",
    "labels[\"user_id\"] = labels[\"user_id\"].astype(str)\n",
    "\n",
    "df = features.merge(\n",
    "    labels[[\"user_id\", \"anchor_time\", \"label\", \"split\"]],\n",
    "    on=[\"user_id\", \"anchor_time\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "df[\"y\"] = (df[\"label\"] == \"m2\").astype(int)\n",
    "\n",
    "drop_cols = [\"user_id\", \"anchor_time\", \"label\", \"split\", \"y\"]\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "train_df = df[df[\"split\"] == \"train\"]\n",
    "val_df = df[df[\"split\"] == \"val\"]\n",
    "test_df = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "X_train, y_train = train_df[feature_cols], train_df[\"y\"].to_numpy()\n",
    "X_val, y_val = val_df[feature_cols], val_df[\"y\"].to_numpy()\n",
    "X_test, y_test = test_df[feature_cols], test_df[\"y\"].to_numpy()\n",
    "\n",
    "X_tv = pd.concat([X_train, X_val], axis=0)\n",
    "y_tv = np.concatenate([y_train, y_val])\n",
    "\n",
    "BEST = tune_lg(X_train, y_train, X_val, y_val, n_trials=30, seed=42)\n",
    "\n",
    "MODEL_NAME = \"lg\"\n",
    "MODEL_ID = \"ml__lg\"\n",
    "VERSION = \"v1_tuned\"\n",
    "\n",
    "final = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    **BEST[\"params\"],\n",
    ")\n",
    "final.fit(X_tv, y_tv)\n",
    "\n",
    "test_prob = final.predict_proba(X_test)[:, 1]\n",
    "test_true = np.asarray(y_test).astype(int)\n",
    "\n",
    "metrics_payload = build_ranking_metrics(test_true, test_prob)\n",
    "figures = make_figures(test_true, test_prob, k_list=(5, 10, 15, 30), cmap=\"Blues\")\n",
    "\n",
    "saved = save_model_and_artifacts(\n",
    "    model=final,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_type=\"ml\",\n",
    "    model_id=MODEL_ID,\n",
    "    split=\"test\",\n",
    "    metrics=metrics_payload,\n",
    "    y_true=test_true,\n",
    "    y_prob=np.asarray(test_prob).astype(float),\n",
    "    version=VERSION,\n",
    "    scaler=None,\n",
    "    figures=figures,\n",
    "    config={\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"model_type\": \"ml\",\n",
    "        \"version\": VERSION,\n",
    "        \"feature_source\": \"features_ml_clean.parquet\",\n",
    "        \"n_features\": int(len(feature_cols)),\n",
    "        \"best_params\": dict_to_py(BEST[\"params\"]),\n",
    "        \"best_val_pr_auc\": float(BEST[\"val_pr_auc\"]),\n",
    "    },\n",
    ")\n",
    "\n",
    "plt.close(figures[\"pr_curve\"])\n",
    "for k in (5, 10, 15, 30):\n",
    "    plt.close(figures[f\"confusion_matrix_top{k}\"])\n",
    "\n",
    "sp = score_percentiles_payload(MODEL_ID, \"test\", test_prob)\n",
    "p_streamlit = write_streamlit_score_percentiles(MODEL_NAME, sp)\n",
    "\n",
    "tuning_payload = {\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"version\": VERSION,\n",
    "    \"best_val_pr_auc\": float(BEST[\"val_pr_auc\"]),\n",
    "    \"best_params\": dict_to_py(BEST[\"params\"]),\n",
    "    \"history\": BEST[\"history\"],\n",
    "}\n",
    "tuning_path = Path(PATHS[\"models_metrics\"]) / MODEL_NAME / VERSION / \"tuning.json\"\n",
    "tuning_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "tuning_path.write_text(json.dumps(tuning_payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6740a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
