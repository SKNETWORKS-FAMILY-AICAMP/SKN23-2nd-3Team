{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 현재 파일 위치 기준으로 위로 올라가며 \"app\" 폴더를 찾는다\n",
    "p = Path.cwd().resolve()\n",
    "for _ in range(6):  # 최대 6단계 위까지 탐색\n",
    "    if (p / \"app\").exists() and (p / \"models\").exists():\n",
    "        sys.path.insert(0, str(p))\n",
    "        print(\"✅ project root added to sys.path:\", p)\n",
    "        break\n",
    "    p = p.parent\n",
    "else:\n",
    "    raise RuntimeError(\"❌ 프로젝트 루트를 찾지 못했어요. app/ 와 models/ 가 있는 폴더에서 실행해야 합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6da934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial 1/30 val_recall_at_10pct=0.11272 val_pr_auc=0.91693 params={\"learning_rate\": 0.05, \"max_depth\": 3, \"max_iter\": 800, \"min_samples_leaf\": 20, \"l2_regularization\": 0.0001, \"max_bins\": 255, \"max_leaf_nodes\": 15, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 2/30 val_recall_at_10pct=0.11276 val_pr_auc=0.91682 params={\"learning_rate\": 0.01, \"max_depth\": 4, \"max_iter\": 800, \"min_samples_leaf\": 100, \"l2_regularization\": 0.01, \"max_bins\": 255, \"max_leaf_nodes\": 127, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 3/30 val_recall_at_10pct=0.11274 val_pr_auc=0.91688 params={\"learning_rate\": 0.01, \"max_depth\": 5, \"max_iter\": 1200, \"min_samples_leaf\": 20, \"l2_regularization\": 0.001, \"max_bins\": 128, \"max_leaf_nodes\": 15, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 4/30 val_recall_at_10pct=0.11264 val_pr_auc=0.91647 params={\"learning_rate\": 0.05, \"max_depth\": 6, \"max_iter\": 500, \"min_samples_leaf\": 50, \"l2_regularization\": 0.001, \"max_bins\": 128, \"max_leaf_nodes\": 63, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 5/30 val_recall_at_10pct=0.11269 val_pr_auc=0.91699 params={\"learning_rate\": 0.03, \"max_depth\": 3, \"max_iter\": 1200, \"min_samples_leaf\": 5, \"l2_regularization\": 0.1, \"max_bins\": 255, \"max_leaf_nodes\": 31, \"max_features\": 0.8, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 6/30 val_recall_at_10pct=0.11272 val_pr_auc=0.91693 params={\"learning_rate\": 0.05, \"max_depth\": 3, \"max_iter\": 800, \"min_samples_leaf\": 20, \"l2_regularization\": 0.0, \"max_bins\": 255, \"max_leaf_nodes\": 63, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 7/30 val_recall_at_10pct=0.11220 val_pr_auc=0.91437 params={\"learning_rate\": 0.05, \"max_depth\": 6, \"max_iter\": 1200, \"min_samples_leaf\": 10, \"l2_regularization\": 0.0001, \"max_bins\": 128, \"max_leaf_nodes\": 63, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 8/30 val_recall_at_10pct=0.11275 val_pr_auc=0.91695 params={\"learning_rate\": 0.01, \"max_depth\": 5, \"max_iter\": 800, \"min_samples_leaf\": 50, \"l2_regularization\": 0.1, \"max_bins\": 255, \"max_leaf_nodes\": 31, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 9/30 val_recall_at_10pct=0.11282 val_pr_auc=0.91679 params={\"learning_rate\": 0.02, \"max_depth\": 5, \"max_iter\": 1200, \"min_samples_leaf\": 20, \"l2_regularization\": 0.0, \"max_bins\": 128, \"max_leaf_nodes\": 127, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 10/30 val_recall_at_10pct=0.11280 val_pr_auc=0.91690 params={\"learning_rate\": 0.01, \"max_depth\": 5, \"max_iter\": 800, \"min_samples_leaf\": 20, \"l2_regularization\": 1e-05, \"max_bins\": 64, \"max_leaf_nodes\": 63, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 11/30 val_recall_at_10pct=0.11272 val_pr_auc=0.91695 params={\"learning_rate\": 0.03, \"max_depth\": null, \"max_iter\": 300, \"min_samples_leaf\": 50, \"l2_regularization\": 0.001, \"max_bins\": 255, \"max_leaf_nodes\": 15, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 12/30 val_recall_at_10pct=0.11276 val_pr_auc=0.91619 params={\"learning_rate\": 0.07, \"max_depth\": 6, \"max_iter\": 500, \"min_samples_leaf\": 50, \"l2_regularization\": 0.1, \"max_bins\": 128, \"max_leaf_nodes\": 255, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 13/30 val_recall_at_10pct=0.11286 val_pr_auc=0.91639 params={\"learning_rate\": 0.05, \"max_depth\": 4, \"max_iter\": 800, \"min_samples_leaf\": 5, \"l2_regularization\": 0.01, \"max_bins\": 64, \"max_leaf_nodes\": 255, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 14/30 val_recall_at_10pct=0.11261 val_pr_auc=0.91563 params={\"learning_rate\": 0.05, \"max_depth\": 6, \"max_iter\": 1200, \"min_samples_leaf\": 30, \"l2_regularization\": 0.0001, \"max_bins\": 255, \"max_leaf_nodes\": 31, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 15/30 val_recall_at_10pct=0.11283 val_pr_auc=0.91671 params={\"learning_rate\": 0.03, \"max_depth\": 5, \"max_iter\": 800, \"min_samples_leaf\": 30, \"l2_regularization\": 0.0, \"max_bins\": 64, \"max_leaf_nodes\": 31, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 16/30 val_recall_at_10pct=0.11265 val_pr_auc=0.91634 params={\"learning_rate\": 0.05, \"max_depth\": 5, \"max_iter\": 800, \"min_samples_leaf\": 20, \"l2_regularization\": 0.1, \"max_bins\": 128, \"max_leaf_nodes\": 15, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 17/30 val_recall_at_10pct=0.11276 val_pr_auc=0.91653 params={\"learning_rate\": 0.05, \"max_depth\": 5, \"max_iter\": 800, \"min_samples_leaf\": 30, \"l2_regularization\": 0.0, \"max_bins\": 128, \"max_leaf_nodes\": 127, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 18/30 val_recall_at_10pct=0.11281 val_pr_auc=0.91673 params={\"learning_rate\": 0.01, \"max_depth\": 6, \"max_iter\": 500, \"min_samples_leaf\": 20, \"l2_regularization\": 0.1, \"max_bins\": 64, \"max_leaf_nodes\": 31, \"max_features\": 0.8, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 19/30 val_recall_at_10pct=0.11214 val_pr_auc=0.91306 params={\"learning_rate\": 0.07, \"max_depth\": null, \"max_iter\": 300, \"min_samples_leaf\": 10, \"l2_regularization\": 0.01, \"max_bins\": 64, \"max_leaf_nodes\": 255, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 20/30 val_recall_at_10pct=0.11271 val_pr_auc=0.91605 params={\"learning_rate\": 0.02, \"max_depth\": null, \"max_iter\": 500, \"min_samples_leaf\": 30, \"l2_regularization\": 0.0, \"max_bins\": 128, \"max_leaf_nodes\": 63, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 21/30 val_recall_at_10pct=0.11253 val_pr_auc=0.91641 params={\"learning_rate\": 0.05, \"max_depth\": null, \"max_iter\": 500, \"min_samples_leaf\": 20, \"l2_regularization\": 0.0001, \"max_bins\": 255, \"max_leaf_nodes\": 31, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 22/30 val_recall_at_10pct=0.11246 val_pr_auc=0.91625 params={\"learning_rate\": 0.01, \"max_depth\": 4, \"max_iter\": 300, \"min_samples_leaf\": 5, \"l2_regularization\": 0.01, \"max_bins\": 255, \"max_leaf_nodes\": 127, \"max_features\": 0.8, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 23/30 val_recall_at_10pct=0.11268 val_pr_auc=0.91665 params={\"learning_rate\": 0.01, \"max_depth\": 6, \"max_iter\": 1200, \"min_samples_leaf\": 30, \"l2_regularization\": 0.1, \"max_bins\": 64, \"max_leaf_nodes\": 63, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 24/30 val_recall_at_10pct=0.11283 val_pr_auc=0.91686 params={\"learning_rate\": 0.03, \"max_depth\": 5, \"max_iter\": 300, \"min_samples_leaf\": 20, \"l2_regularization\": 1e-05, \"max_bins\": 64, \"max_leaf_nodes\": 127, \"max_features\": 0.8, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 25/30 val_recall_at_10pct=0.11266 val_pr_auc=0.91614 params={\"learning_rate\": 0.02, \"max_depth\": 6, \"max_iter\": 1200, \"min_samples_leaf\": 5, \"l2_regularization\": 0.0001, \"max_bins\": 64, \"max_leaf_nodes\": 31, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 26/30 val_recall_at_10pct=0.11274 val_pr_auc=0.91637 params={\"learning_rate\": 0.07, \"max_depth\": 4, \"max_iter\": 500, \"min_samples_leaf\": 50, \"l2_regularization\": 0.0001, \"max_bins\": 64, \"max_leaf_nodes\": 127, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 27/30 val_recall_at_10pct=0.11275 val_pr_auc=0.91651 params={\"learning_rate\": 0.05, \"max_depth\": 4, \"max_iter\": 500, \"min_samples_leaf\": 50, \"l2_regularization\": 0.01, \"max_bins\": 128, \"max_leaf_nodes\": 127, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 28/30 val_recall_at_10pct=0.11260 val_pr_auc=0.91588 params={\"learning_rate\": 0.01, \"max_depth\": 3, \"max_iter\": 500, \"min_samples_leaf\": 100, \"l2_regularization\": 0.0, \"max_bins\": 128, \"max_leaf_nodes\": 127, \"max_features\": 0.6, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 29/30 val_recall_at_10pct=0.11272 val_pr_auc=0.91651 params={\"learning_rate\": 0.02, \"max_depth\": 6, \"max_iter\": 1200, \"min_samples_leaf\": 30, \"l2_regularization\": 0.001, \"max_bins\": 64, \"max_leaf_nodes\": 63, \"max_features\": 1.0, \"random_state\": 42, \"early_stopping\": false}\n",
      "trial 30/30 val_recall_at_10pct=0.11281 val_pr_auc=0.91688 params={\"learning_rate\": 0.05, \"max_depth\": 3, \"max_iter\": 500, \"min_samples_leaf\": 50, \"l2_regularization\": 0.001, \"max_bins\": 128, \"max_leaf_nodes\": 31, \"max_features\": 0.8, \"random_state\": 42, \"early_stopping\": false}\n",
      "best_val_recall_k: 0.11286089238845144\n",
      "best_val_pr_auc: 0.9163882500186006\n",
      "best_params: {\n",
      "  \"learning_rate\": 0.05,\n",
      "  \"max_depth\": 4,\n",
      "  \"max_iter\": 800,\n",
      "  \"min_samples_leaf\": 5,\n",
      "  \"l2_regularization\": 0.01,\n",
      "  \"max_bins\": 64,\n",
      "  \"max_leaf_nodes\": 255,\n",
      "  \"max_features\": 0.6,\n",
      "  \"random_state\": 42,\n",
      "  \"early_stopping\": false\n",
      "}\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"split\": \"test\",\n",
      "  \"percentiles\": [\n",
      "    {\n",
      "      \"pct\": 1,\n",
      "      \"score\": 0.8037301149505969\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 5,\n",
      "      \"score\": 0.790988305238898\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 10,\n",
      "      \"score\": 0.7724576274496469\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 20,\n",
      "      \"score\": 0.7197264260306521\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 30,\n",
      "      \"score\": 0.6758677370132594\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 50,\n",
      "      \"score\": 0.5861709818217891\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_score_percentiles.json\n",
      "{\n",
      "  \"PR-AUC (Average Precision)\": 0.9331818676699821,\n",
      "  \"ranking\": [\n",
      "    {\n",
      "      \"Top_K\": \"5%\",\n",
      "      \"Precision\": 0.9671970143390297,\n",
      "      \"Recall\": 0.055763176371996105,\n",
      "      \"Lift\": 1.115405920151145\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"10%\",\n",
      "      \"Precision\": 0.9629775115388393,\n",
      "      \"Recall\": 0.11105071232814659,\n",
      "      \"Lift\": 1.110539839783183\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"15%\",\n",
      "      \"Precision\": 0.9605866177818515,\n",
      "      \"Recall\": 0.1661570519354035,\n",
      "      \"Lift\": 1.1077825762562488\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"20%\",\n",
      "      \"Precision\": 0.9545320632426594,\n",
      "      \"Recall\": 0.2201535639056873,\n",
      "      \"Lift\": 1.1008002491018294\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"25%\",\n",
      "      \"Precision\": 0.9508602403959463,\n",
      "      \"Recall\": 0.27413875110416525,\n",
      "      \"Lift\": 1.0965657726919027\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"30%\",\n",
      "      \"Precision\": 0.9473305181839012,\n",
      "      \"Recall\": 0.32773889606124434,\n",
      "      \"Lift\": 1.092495171776644\n",
      "    }\n",
      "  ],\n",
      "  \"상위 5% 정밀도 (Precision)\": 0.9671970143390297,\n",
      "  \"상위 5% 재현율 (Recall)\": 0.055763176371996105,\n",
      "  \"상위 5% 리프트 (Lift)\": 1.115405920151145,\n",
      "  \"selection_rule\": \"val Recall@10% then PR-AUC\",\n",
      "  \"best_val_recall_at_k\": 0.11286089238845144,\n",
      "  \"best_val_pr_auc\": 0.9163882500186006\n",
      "}\n",
      "saved paths:\n",
      "model: /Users/jy/project_2nd/SKN23-2nd-3Team/models/ml/hgb/tuned_on_val/model.pkl\n",
      "config: /Users/jy/project_2nd/SKN23-2nd-3Team/models/configs/hgb/tuned_on_val/config.json\n",
      "eval_dir: /Users/jy/project_2nd/SKN23-2nd-3Team/models/eval/mlhgb\n",
      "version_dir: tuned_on_val\n",
      "figure_pr_curve: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/pr_curve.png\n",
      "figure_confusion_matrix_top5: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/confusion_matrix_top5.png\n",
      "figure_confusion_matrix_top10: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/confusion_matrix_top10.png\n",
      "figure_confusion_matrix_top15: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/confusion_matrix_top15.png\n",
      "figure_confusion_matrix_top30: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/confusion_matrix_top30.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/jy/project_2nd/SKN23-2nd-3Team\")\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from app.utils.save import save_model_and_artifacts\n",
    "\n",
    "try:\n",
    "    from app.utils.plotting import configure_matplotlib_korean\n",
    "    configure_matplotlib_korean()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "def recall_at_topk(y_true, y_prob, k_pct: int) -> float:\n",
    "    y_true = np.asarray(y_true).astype(int).reshape(-1)\n",
    "    y_prob = np.asarray(y_prob).astype(float).reshape(-1)\n",
    "    order = np.argsort(-y_prob)\n",
    "    n = max(int(np.floor(len(y_true) * (k_pct / 100.0))), 1)\n",
    "    top_idx = order[:n]\n",
    "    return float(y_true[top_idx].sum() / max(y_true.sum(), 1))\n",
    "\n",
    "\n",
    "def precision_at_topk(y_true, y_prob, k_pct: int) -> float:\n",
    "    y_true = np.asarray(y_true).astype(int).reshape(-1)\n",
    "    y_prob = np.asarray(y_prob).astype(float).reshape(-1)\n",
    "    order = np.argsort(-y_prob)\n",
    "    n = max(int(np.floor(len(y_true) * (k_pct / 100.0))), 1)\n",
    "    top_idx = order[:n]\n",
    "    return float(y_true[top_idx].mean())\n",
    "\n",
    "\n",
    "def lift_at_topk(y_true, y_prob, k_pct: int) -> float:\n",
    "    y_true = np.asarray(y_true).astype(int).reshape(-1)\n",
    "    base = float(y_true.mean())\n",
    "    pk = precision_at_topk(y_true, y_prob, k_pct)\n",
    "    return float(pk / base) if base > 0 else 0.0\n",
    "\n",
    "\n",
    "def build_ranking_metrics(y_true, y_prob, k_list=(5, 10, 15, 20, 25, 30)):\n",
    "    y_true = np.asarray(y_true).astype(int).reshape(-1)\n",
    "    y_prob = np.asarray(y_prob).astype(float).reshape(-1)\n",
    "\n",
    "    pr_auc = float(average_precision_score(y_true, y_prob))\n",
    "\n",
    "    df_rank = pd.DataFrame({\"y\": y_true, \"score\": y_prob}).sort_values(\"score\", ascending=False)\n",
    "    base_rate = float(df_rank[\"y\"].mean())\n",
    "    total_pos = float(df_rank[\"y\"].sum())\n",
    "    n_total = len(df_rank)\n",
    "\n",
    "    ranking = []\n",
    "    for k in k_list:\n",
    "        n_sel = max(int(np.floor(n_total * k / 100)), 1)\n",
    "        selected = df_rank.iloc[:n_sel]\n",
    "\n",
    "        precision_k = float(selected[\"y\"].mean())\n",
    "        recall_k = float(selected[\"y\"].sum() / (total_pos + 1e-12))\n",
    "        lift_k = float(precision_k / base_rate) if base_rate > 0 else 0.0\n",
    "\n",
    "        ranking.append({\"Top_K\": f\"{k}%\", \"Precision\": precision_k, \"Recall\": recall_k, \"Lift\": lift_k})\n",
    "\n",
    "    out = {\"PR-AUC (Average Precision)\": pr_auc, \"ranking\": ranking}\n",
    "    for row in ranking:\n",
    "        if row[\"Top_K\"] == \"5%\":\n",
    "            out[\"상위 5% 정밀도 (Precision)\"] = row[\"Precision\"]\n",
    "            out[\"상위 5% 재현율 (Recall)\"] = row[\"Recall\"]\n",
    "            out[\"상위 5% 리프트 (Lift)\"] = row[\"Lift\"]\n",
    "            break\n",
    "    return out\n",
    "\n",
    "\n",
    "def score_percentiles_payload(model_id: str, split: str, y_prob, pcts=(1, 5, 10, 20, 30, 50)):\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    percentiles = [{\"pct\": int(p), \"score\": float(np.quantile(y_prob, 1.0 - p / 100.0))} for p in pcts]\n",
    "    return {\"model_id\": model_id, \"split\": split, \"percentiles\": percentiles}\n",
    "\n",
    "\n",
    "def _stem_from_model_id(model_id: str) -> str:\n",
    "    if model_id.startswith(\"dl__mlp_\"):\n",
    "        return \"mlp_\" + model_id.split(\"dl__mlp_\", 1)[1]\n",
    "    if model_id.startswith(\"ml__\"):\n",
    "        return model_id.split(\"ml__\", 1)[1]\n",
    "    if model_id.startswith(\"dl__\"):\n",
    "        return model_id.split(\"dl__\", 1)[1]\n",
    "    return model_id\n",
    "\n",
    "\n",
    "def save_and_print_score_percentiles(PROJECT_ROOT: Path, model_id: str, split: str, y_prob):\n",
    "    metrics_dir = PROJECT_ROOT / \"models\" / \"metrics\"\n",
    "    metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    payload = score_percentiles_payload(model_id, split, y_prob, pcts=(1, 5, 10, 20, 30, 50))\n",
    "    out_path = metrics_dir / f\"{_stem_from_model_id(model_id)}_score_percentiles.json\"\n",
    "    out_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(json.dumps(payload, ensure_ascii=False, indent=2))\n",
    "    print(str(out_path))\n",
    "    return payload, out_path\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, labels=(\"비이탈(m1)\", \"이탈(m2)\"), cmap=\"Blues\"):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(cm, cmap=cmap, interpolation=\"nearest\", aspect=\"equal\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    thresh = cm.max() / 2.0 if cm.size else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(\n",
    "                j, i, f\"{cm[i, j]}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                fontsize=12,\n",
    "            )\n",
    "\n",
    "    ax.set_xlim(-0.5, cm.shape[1] - 0.5)\n",
    "    ax.set_ylim(cm.shape[0] - 0.5, -0.5)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def threshold_topk(y_prob, k_pct: int) -> float:\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    order = np.argsort(-y_prob)\n",
    "    n_sel = max(int(np.floor(len(y_prob) * k_pct / 100)), 1)\n",
    "    return float(y_prob[order[n_sel - 1]])\n",
    "\n",
    "\n",
    "def make_sample_weight(y: np.ndarray) -> np.ndarray:\n",
    "    y = np.asarray(y).astype(int).reshape(-1)\n",
    "    pos = float((y == 1).sum())\n",
    "    neg = float((y == 0).sum())\n",
    "    if pos == 0:\n",
    "        return np.ones_like(y, dtype=float)\n",
    "    w_pos = neg / pos\n",
    "    w = np.ones_like(y, dtype=float)\n",
    "    w[y == 1] = w_pos\n",
    "    return w\n",
    "\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "features = pd.read_parquet(DATA_DIR / \"features_ml_clean.parquet\")\n",
    "labels = pd.read_parquet(DATA_DIR / \"labels.parquet\")\n",
    "\n",
    "features[\"user_id\"] = features[\"user_id\"].astype(str)\n",
    "labels[\"user_id\"] = labels[\"user_id\"].astype(str)\n",
    "\n",
    "df = features.merge(\n",
    "    labels[[\"user_id\", \"anchor_time\", \"label\", \"split\"]],\n",
    "    on=[\"user_id\", \"anchor_time\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "df[\"y\"] = (df[\"label\"] == \"m2\").astype(int)\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [\"user_id\", \"anchor_time\", \"label\", \"split\", \"y\"]]\n",
    "\n",
    "train_df = df[df[\"split\"] == \"train\"]\n",
    "val_df = df[df[\"split\"] == \"val\"]\n",
    "test_df = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "X_train, y_train = train_df[feature_cols], train_df[\"y\"].to_numpy(dtype=int)\n",
    "X_val, y_val = val_df[feature_cols], val_df[\"y\"].to_numpy(dtype=int)\n",
    "X_test, y_test = test_df[feature_cols], test_df[\"y\"].to_numpy(dtype=int)\n",
    "\n",
    "\n",
    "BEST_K_PCT = 10\n",
    "N_TRIALS = 30\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "def tune_hgb_on_val(X_train, y_train, X_val, y_val, n_trials=30, seed=42, best_k_pct=10):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    best = {\n",
    "        \"val_recall_k\": -1.0,\n",
    "        \"val_pr_auc\": -1.0,\n",
    "        \"params\": None,\n",
    "    }\n",
    "\n",
    "    sw_train = make_sample_weight(y_train)\n",
    "\n",
    "    for t in range(int(n_trials)):\n",
    "        max_depth_choice = rng.choice([3, 4, 5, 6, None])\n",
    "\n",
    "        params = {\n",
    "            \"learning_rate\": float(rng.choice([0.01, 0.02, 0.03, 0.05, 0.07])),\n",
    "            \"max_depth\": None if max_depth_choice is None else int(max_depth_choice),\n",
    "            \"max_iter\": int(rng.choice([300, 500, 800, 1200])),\n",
    "            \"min_samples_leaf\": int(rng.choice([5, 10, 20, 30, 50, 100])),\n",
    "            \"l2_regularization\": float(rng.choice([0.0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1])),\n",
    "            \"max_bins\": int(rng.choice([64, 128, 255])),\n",
    "            \"max_leaf_nodes\": int(rng.choice([15, 31, 63, 127, 255])),\n",
    "            \"max_features\": float(rng.choice([0.6, 0.8, 1.0])),\n",
    "            \"random_state\": int(seed),\n",
    "            \"early_stopping\": False,\n",
    "        }\n",
    "\n",
    "        model = HistGradientBoostingClassifier(**params)\n",
    "        model.fit(X_train, y_train, sample_weight=sw_train)\n",
    "\n",
    "        val_prob = model.predict_proba(X_val)[:, 1]\n",
    "        val_pr_auc = float(average_precision_score(y_val, val_prob))\n",
    "        val_recall_k = recall_at_topk(y_val, val_prob, best_k_pct)\n",
    "\n",
    "        print(\n",
    "            f\"trial {t+1}/{n_trials} \"\n",
    "            f\"val_recall_at_{best_k_pct}pct={val_recall_k:.5f} \"\n",
    "            f\"val_pr_auc={val_pr_auc:.5f} \"\n",
    "            f\"params={json.dumps(params, ensure_ascii=False)}\"\n",
    "        )\n",
    "\n",
    "        better = (val_recall_k > best[\"val_recall_k\"] + 1e-12) or (\n",
    "            abs(val_recall_k - best[\"val_recall_k\"]) <= 1e-12 and val_pr_auc > best[\"val_pr_auc\"]\n",
    "        )\n",
    "        if better:\n",
    "            best[\"val_recall_k\"] = val_recall_k\n",
    "            best[\"val_pr_auc\"] = val_pr_auc\n",
    "            best[\"params\"] = params\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "tune_result = tune_hgb_on_val(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    n_trials=N_TRIALS,\n",
    "    seed=SEED,\n",
    "    best_k_pct=BEST_K_PCT,\n",
    ")\n",
    "\n",
    "best_params = tune_result[\"params\"]\n",
    "best_val_recall_k = tune_result[\"val_recall_k\"]\n",
    "best_val_pr_auc = tune_result[\"val_pr_auc\"]\n",
    "\n",
    "print(\"best_val_recall_k:\", best_val_recall_k)\n",
    "print(\"best_val_pr_auc:\", best_val_pr_auc)\n",
    "print(\"best_params:\", json.dumps(best_params, ensure_ascii=False, indent=2))\n",
    "\n",
    "\n",
    "X_tv = pd.concat([X_train, X_val], axis=0)\n",
    "y_tv = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "sw_tv = make_sample_weight(y_tv)\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(**best_params)\n",
    "hgb.fit(X_tv, y_tv, sample_weight=sw_tv)\n",
    "\n",
    "test_prob = hgb.predict_proba(X_test)[:, 1]\n",
    "test_true = np.asarray(y_test).astype(int)\n",
    "\n",
    "MODEL_ID = \"ml__hgb\"\n",
    "SPLIT = \"test\"\n",
    "\n",
    "save_and_print_score_percentiles(PROJECT_ROOT, MODEL_ID, SPLIT, test_prob)\n",
    "\n",
    "metrics_payload = build_ranking_metrics(test_true, test_prob, k_list=(5, 10, 15, 20, 25, 30))\n",
    "metrics_payload[\"selection_rule\"] = f\"val Recall@{BEST_K_PCT}% then PR-AUC\"\n",
    "metrics_payload[\"best_val_recall_at_k\"] = float(best_val_recall_k)\n",
    "metrics_payload[\"best_val_pr_auc\"] = float(best_val_pr_auc)\n",
    "\n",
    "print(json.dumps(metrics_payload, ensure_ascii=False, indent=2))\n",
    "\n",
    "pr_auc_val = float(metrics_payload[\"PR-AUC (Average Precision)\"])\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(test_true, test_prob)\n",
    "fig_pr, ax_pr = plt.subplots(figsize=(6, 5))\n",
    "ax_pr.plot(recall, precision, lw=2, label=f\"PR-AUC = {pr_auc_val:.5f}\")\n",
    "ax_pr.set_xlabel(\"Recall\")\n",
    "ax_pr.set_ylabel(\"Precision\")\n",
    "ax_pr.set_title(\"Precision-Recall Curve\")\n",
    "ax_pr.legend()\n",
    "ax_pr.grid(alpha=0.3)\n",
    "fig_pr.tight_layout()\n",
    "\n",
    "k_list = [5, 10, 15, 30]\n",
    "figures = {\"pr_curve\": fig_pr}\n",
    "\n",
    "for k in k_list:\n",
    "    thr = threshold_topk(test_prob, k)\n",
    "    y_pred_k = (np.asarray(test_prob) >= thr).astype(int)\n",
    "    figures[f\"confusion_matrix_top{k}\"] = plot_confusion_matrix(\n",
    "        test_true,\n",
    "        y_pred_k,\n",
    "        title=f\"Confusion Matrix (Top {k}%, thr={thr:.5f})\",\n",
    "        labels=(\"비이탈(m1)\", \"이탈(m2)\"),\n",
    "        cmap=\"Blues\",\n",
    "    )\n",
    "\n",
    "saved = save_model_and_artifacts(\n",
    "    model=hgb,\n",
    "    model_name=\"hgb\",\n",
    "    model_type=\"ml\",\n",
    "    model_id=MODEL_ID,\n",
    "    split=SPLIT,\n",
    "    metrics=metrics_payload,\n",
    "    y_true=test_true,\n",
    "    y_prob=np.asarray(test_prob).astype(float),\n",
    "    version=\"tuned_on_val\",\n",
    "    scaler=None,\n",
    "    figures=figures,\n",
    "    config={\n",
    "        \"model_name\": \"hgb\",\n",
    "        \"model_type\": \"ml\",\n",
    "        \"version\": \"tuned_on_val\",\n",
    "        \"feature_source\": \"features_ml_clean.parquet\",\n",
    "        \"best_selection\": f\"val Recall@{BEST_K_PCT}%\",\n",
    "        \"use_sample_weight\": True,\n",
    "        \"note\": \"hp tuned on train/val, retrained train+val, test evaluated once\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"saved paths:\")\n",
    "for k, v in saved.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "plt.close(fig_pr)\n",
    "for k in k_list:\n",
    "    plt.close(figures[f\"confusion_matrix_top{k}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace82682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
