{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6da934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_val_pr_auc: 0.916921204669227\n",
      "best_params: {\n",
      "  \"learning_rate\": 0.05,\n",
      "  \"max_depth\": 3,\n",
      "  \"max_iter\": 800,\n",
      "  \"min_samples_leaf\": 20,\n",
      "  \"l2_regularization\": 0.01,\n",
      "  \"max_bins\": 64,\n",
      "  \"random_state\": 42\n",
      "}\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"split\": \"test\",\n",
      "  \"percentiles\": [\n",
      "    {\n",
      "      \"pct\": 1,\n",
      "      \"score\": 0.9445879419430825\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 5,\n",
      "      \"score\": 0.9386033626970024\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 10,\n",
      "      \"score\": 0.9316305644647573\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 20,\n",
      "      \"score\": 0.9164893802819916\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 30,\n",
      "      \"score\": 0.8989172283549766\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 50,\n",
      "      \"score\": 0.8581260113204877\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_score_percentiles.json\n",
      "{\n",
      "  \"PR-AUC (Average Precision)\": 0.9330339316187535,\n",
      "  \"상위 5% 정밀도 (Precision)\": 0.9685719897858966,\n",
      "  \"상위 5% 재현율 (Recall)\": 0.055842449774637044,\n",
      "  \"상위 5% 리프트 (Lift)\": 1.116991590630645,\n",
      "  \"ranking\": [\n",
      "    {\n",
      "      \"Top_K\": \"5%\",\n",
      "      \"Precision\": 0.9685719897858966,\n",
      "      \"Recall\": 0.055842449774637044,\n",
      "      \"Lift\": 1.116991590630645\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"10%\",\n",
      "      \"Precision\": 0.9630757144260041,\n",
      "      \"Recall\": 0.11106203709995244,\n",
      "      \"Lift\": 1.1106530908376173\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"15%\",\n",
      "      \"Precision\": 0.9592772030902187,\n",
      "      \"Recall\": 0.16593055649928654,\n",
      "      \"Lift\": 1.1062725127662594\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"20%\",\n",
      "      \"Precision\": 0.9538446430325052,\n",
      "      \"Recall\": 0.21999501710040542,\n",
      "      \"Lift\": 1.1000074917207887\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"25%\",\n",
      "      \"Precision\": 0.9507031188624401,\n",
      "      \"Recall\": 0.27409345201694185,\n",
      "      \"Lift\": 1.0963845745636436\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"30%\",\n",
      "      \"Precision\": 0.9476578611411175,\n",
      "      \"Recall\": 0.32785214377930283,\n",
      "      \"Lift\": 1.092872675291425\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "saved paths:\n",
      "model: /Users/jy/project_2nd/SKN23-2nd-3Team/models/ml/hgb/tuned_on_val/model.pkl\n",
      "metrics: /Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb/tuned_on_val/metrics.json\n",
      "figure_pr_curve: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/pr_curve.png\n",
      "figure_confusion_matrix_top5: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/confusion_matrix_top5.png\n",
      "figure_confusion_matrix_top10: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/confusion_matrix_top10.png\n",
      "figure_confusion_matrix_top15: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/confusion_matrix_top15.png\n",
      "figure_confusion_matrix_top30: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/tuned_on_val/confusion_matrix_top30.png\n",
      "config: /Users/jy/project_2nd/SKN23-2nd-3Team/models/configs/hgb/tuned_on_val/config.json\n",
      "eval_dir: /Users/jy/project_2nd/SKN23-2nd-3Team/models/eval/mlhgb\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/jy/project_2nd/SKN23-2nd-3Team\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from app.utils.save import save_model_and_artifacts\n",
    "\n",
    "try:\n",
    "    from app.utils.plotting import configure_matplotlib_korean\n",
    "    configure_matplotlib_korean()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "# \n",
    "# 공통: metrics / percentiles 출력&저장 유틸\n",
    "# \n",
    "def build_ranking_metrics(y_true, y_prob, k_list=(5, 10, 15, 20, 25, 30)):\n",
    "    y_true = np.asarray(y_true).astype(int).reshape(-1)\n",
    "    y_prob = np.asarray(y_prob).astype(float).reshape(-1)\n",
    "\n",
    "    pr_auc = float(average_precision_score(y_true, y_prob))\n",
    "\n",
    "    df_rank = pd.DataFrame({\"y\": y_true, \"score\": y_prob}).sort_values(\"score\", ascending=False)\n",
    "    base_rate = float(df_rank[\"y\"].mean())\n",
    "    total_pos = float(df_rank[\"y\"].sum())\n",
    "    n_total = len(df_rank)\n",
    "\n",
    "    ranking = []\n",
    "    for k in k_list:\n",
    "        n_sel = max(int(np.floor(n_total * k / 100)), 1)\n",
    "        selected = df_rank.iloc[:n_sel]\n",
    "\n",
    "        precision_k = float(selected[\"y\"].mean())\n",
    "        recall_k = float(selected[\"y\"].sum() / (total_pos + 1e-12))\n",
    "        lift_k = float(precision_k / base_rate) if base_rate > 0 else 0.0\n",
    "\n",
    "        ranking.append({\"Top_K\": f\"{k}%\", \"Precision\": precision_k, \"Recall\": recall_k, \"Lift\": lift_k})\n",
    "\n",
    "    return {\n",
    "        \"PR-AUC (Average Precision)\": pr_auc,\n",
    "        \"상위 5% 정밀도 (Precision)\": ranking[0][\"Precision\"],\n",
    "        \"상위 5% 재현율 (Recall)\": ranking[0][\"Recall\"],\n",
    "        \"상위 5% 리프트 (Lift)\": ranking[0][\"Lift\"],\n",
    "        \"ranking\": ranking,\n",
    "    }\n",
    "\n",
    "\n",
    "def score_percentiles_payload(model_id: str, split: str, y_prob, pcts=(1, 5, 10, 20, 30, 50)):\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    percentiles = [{\"pct\": int(p), \"score\": float(np.quantile(y_prob, 1.0 - p / 100.0))} for p in pcts]\n",
    "    return {\"model_id\": model_id, \"split\": split, \"percentiles\": percentiles}\n",
    "\n",
    "\n",
    "def _stem_from_model_id(model_id: str) -> str:\n",
    "    if model_id.startswith(\"dl__mlp_\"):\n",
    "        return \"mlp_\" + model_id.split(\"dl__mlp_\", 1)[1]\n",
    "    if model_id.startswith(\"ml__\"):\n",
    "        return model_id.split(\"ml__\", 1)[1]\n",
    "    if model_id.startswith(\"dl__\"):\n",
    "        return model_id.split(\"dl__\", 1)[1]\n",
    "    return model_id\n",
    "\n",
    "\n",
    "def save_and_print_score_percentiles(PROJECT_ROOT: Path, model_id: str, split: str, y_prob):\n",
    "    metrics_dir = PROJECT_ROOT / \"models\" / \"metrics\"\n",
    "    metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    payload = score_percentiles_payload(model_id, split, y_prob, pcts=(1, 5, 10, 20, 30, 50))\n",
    "    out_path = metrics_dir / f\"{_stem_from_model_id(model_id)}_score_percentiles.json\"\n",
    "    out_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(json.dumps(payload, ensure_ascii=False, indent=2))\n",
    "    print(str(out_path))\n",
    "    return payload, out_path\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, labels=(\"비이탈(m1)\", \"이탈(m2)\"), cmap=\"Blues\"):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(cm, cmap=cmap, interpolation=\"nearest\", aspect=\"equal\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted (예측값)\")\n",
    "    ax.set_ylabel(\"Actual (실제값)\")\n",
    "\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    thresh = cm.max() / 2.0 if cm.size else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(\n",
    "                j, i, f\"{cm[i, j]}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                fontsize=12,\n",
    "            )\n",
    "\n",
    "    ax.set_xlim(-0.5, cm.shape[1] - 0.5)\n",
    "    ax.set_ylim(cm.shape[0] - 0.5, -0.5)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def threshold_topk(y_prob, k_pct: int) -> float:\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    order = np.argsort(-y_prob)\n",
    "    n_sel = max(int(np.floor(len(y_prob) * k_pct / 100)), 1)\n",
    "    return float(y_prob[order[n_sel - 1]])\n",
    "\n",
    "\n",
    "# \n",
    "# 1) 데이터 로드 & split 분리 (팀 규칙 준수)\n",
    "# \n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "features = pd.read_parquet(DATA_DIR / \"features_ml_clean.parquet\")\n",
    "labels = pd.read_parquet(DATA_DIR / \"labels.parquet\")\n",
    "\n",
    "features[\"user_id\"] = features[\"user_id\"].astype(str)\n",
    "labels[\"user_id\"] = labels[\"user_id\"].astype(str)\n",
    "\n",
    "df = features.merge(\n",
    "    labels[[\"user_id\", \"anchor_time\", \"label\", \"split\"]],\n",
    "    on=[\"user_id\", \"anchor_time\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "df[\"y\"] = (df[\"label\"] == \"m2\").astype(int)\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [\"user_id\", \"anchor_time\", \"label\", \"split\", \"y\"]]\n",
    "\n",
    "train_df = df[df[\"split\"] == \"train\"]\n",
    "val_df = df[df[\"split\"] == \"val\"]\n",
    "test_df = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "X_train, y_train = train_df[feature_cols], train_df[\"y\"]\n",
    "X_val, y_val = val_df[feature_cols], val_df[\"y\"]\n",
    "X_test, y_test = test_df[feature_cols], test_df[\"y\"]\n",
    "\n",
    "\n",
    "# \n",
    "# 2) HGB 하이퍼파라미터 튜닝 (VAL 기준, TEST는 마지막 1회)\n",
    "# \n",
    "def tune_hgb_on_val(X_train, y_train, X_val, y_val, n_trials=25, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    best = {\"pr_auc\": -1.0, \"params\": None}\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "        max_depth_choice = rng.choice([3, 4, 5, 6, 7, None])\n",
    "        params = {\n",
    "            \"learning_rate\": float(rng.choice([0.02, 0.03, 0.05, 0.07, 0.1])),\n",
    "            \"max_depth\": None if max_depth_choice is None else int(max_depth_choice),\n",
    "            \"max_iter\": int(rng.choice([200, 300, 500, 800])),\n",
    "            \"min_samples_leaf\": int(rng.choice([10, 20, 30, 50, 100])),\n",
    "            \"l2_regularization\": float(rng.choice([0.0, 1e-4, 1e-3, 1e-2, 1e-1])),\n",
    "            \"max_bins\": int(rng.choice([64, 128, 255])),\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "\n",
    "        model = HistGradientBoostingClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_prob = model.predict_proba(X_val)[:, 1]\n",
    "        pr_auc = float(average_precision_score(np.asarray(y_val), val_prob))\n",
    "\n",
    "        if pr_auc > best[\"pr_auc\"]:\n",
    "            best = {\"pr_auc\": pr_auc, \"params\": params}\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "tune_result = tune_hgb_on_val(X_train, y_train, X_val, y_val, n_trials=25, seed=42)\n",
    "best_params = tune_result[\"params\"]\n",
    "best_val_pr_auc = tune_result[\"pr_auc\"]\n",
    "\n",
    "print(\"best_val_pr_auc:\", best_val_pr_auc)\n",
    "print(\"best_params:\", json.dumps(best_params, ensure_ascii=False, indent=2))\n",
    "\n",
    "\n",
    "# \n",
    "# 3) 최종 학습: train+val로 재학습 후 test 1회 평가\n",
    "# \n",
    "X_tv = pd.concat([X_train, X_val], axis=0)\n",
    "y_tv = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(**best_params)\n",
    "hgb.fit(X_tv, y_tv)\n",
    "\n",
    "test_prob = hgb.predict_proba(X_test)[:, 1]\n",
    "test_true = np.asarray(y_test).astype(int)\n",
    "\n",
    "\n",
    "# \n",
    "# 4) 출력(콘솔): percentiles JSON + 경로 + metrics JSON\n",
    "# \n",
    "MODEL_ID = \"ml__hgb\"\n",
    "SPLIT = \"test\"\n",
    "\n",
    "save_and_print_score_percentiles(PROJECT_ROOT, MODEL_ID, SPLIT, test_prob)\n",
    "\n",
    "metrics_payload = build_ranking_metrics(test_true, test_prob, k_list=(5, 10, 15, 20, 25, 30))\n",
    "print(json.dumps(metrics_payload, ensure_ascii=False, indent=2))\n",
    "\n",
    "\n",
    "# \n",
    "# 5) 그림: PR 커브 + TopK confusion (DL 형식)\n",
    "# \n",
    "pr_auc_val = float(metrics_payload[\"PR-AUC (Average Precision)\"])\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(test_true, test_prob)\n",
    "fig_pr, ax_pr = plt.subplots(figsize=(6, 5))\n",
    "ax_pr.plot(recall, precision, lw=2, label=f\"PR-AUC = {pr_auc_val:.5f}\")\n",
    "ax_pr.set_xlabel(\"Recall\")\n",
    "ax_pr.set_ylabel(\"Precision\")\n",
    "ax_pr.set_title(\"Precision-Recall Curve\")\n",
    "ax_pr.legend()\n",
    "ax_pr.grid(alpha=0.3)\n",
    "fig_pr.tight_layout()\n",
    "\n",
    "k_list = [5, 10, 15, 30]\n",
    "figures = {\"pr_curve\": fig_pr}\n",
    "\n",
    "for k in k_list:\n",
    "    thr = threshold_topk(test_prob, k)\n",
    "    y_pred_k = (np.asarray(test_prob) >= thr).astype(int)\n",
    "    figures[f\"confusion_matrix_top{k}\"] = plot_confusion_matrix(\n",
    "        test_true,\n",
    "        y_pred_k,\n",
    "        title=f\"Confusion Matrix (Top {k}%, thr={thr:.5f})\",\n",
    "        labels=(\"비이탈(m1)\", \"이탈(m2)\"),\n",
    "        cmap=\"Blues\",\n",
    "    )\n",
    "\n",
    "\n",
    "# \n",
    "# 6) 저장: save_model_and_artifacts (DL과 동일 흐름)\n",
    "# \n",
    "saved = save_model_and_artifacts(\n",
    "    model=hgb,\n",
    "    model_name=\"hgb\",\n",
    "    model_type=\"ml\",\n",
    "    model_id=MODEL_ID,\n",
    "    split=SPLIT,\n",
    "    metrics=metrics_payload,\n",
    "    y_true=test_true,\n",
    "    y_prob=np.asarray(test_prob).astype(float),\n",
    "    version=\"tuned_on_val\",\n",
    "    scaler=None,\n",
    "    figures=figures,\n",
    ")\n",
    "\n",
    "print(\"saved paths:\")\n",
    "for k, v in saved.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "plt.close(fig_pr)\n",
    "for k in k_list:\n",
    "    plt.close(figures[f\"confusion_matrix_top{k}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d00a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[v1_baseline] best_val_pr_auc: 0.9169934267257506\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"split\": \"test\",\n",
      "  \"percentiles\": [\n",
      "    {\n",
      "      \"pct\": 1,\n",
      "      \"score\": 0.9489377643618517\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 5,\n",
      "      \"score\": 0.939537315663729\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 10,\n",
      "      \"score\": 0.9335220927435196\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 20,\n",
      "      \"score\": 0.9177193105638359\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 30,\n",
      "      \"score\": 0.8983512475413901\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 50,\n",
      "      \"score\": 0.8581209789815387\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v1_baseline_score_percentiles.json\n",
      "{\n",
      "  \"PR-AUC (Average Precision)\": 0.9332246854198079,\n",
      "  \"상위 5% 정밀도 (Precision)\": 0.966214889019839,\n",
      "  \"상위 5% 재현율 (Recall)\": 0.05570655251296686,\n",
      "  \"상위 5% 리프트 (Lift)\": 1.1142732983800736,\n",
      "  \"ranking\": [\n",
      "    {\n",
      "      \"Top_K\": \"5%\",\n",
      "      \"Precision\": 0.966214889019839,\n",
      "      \"Recall\": 0.05570655251296686,\n",
      "      \"Lift\": 1.1142732983800736\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"10%\",\n",
      "      \"Precision\": 0.9625846999901797,\n",
      "      \"Recall\": 0.1110054132409232,\n",
      "      \"Lift\": 1.1100868355654454\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"15%\",\n",
      "      \"Precision\": 0.9589498494173104,\n",
      "      \"Recall\": 0.1658739326402573,\n",
      "      \"Lift\": 1.105894996893762\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"20%\",\n",
      "      \"Precision\": 0.9541392516939998,\n",
      "      \"Recall\": 0.2200629657312405,\n",
      "      \"Lift\": 1.1003472448840919\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"25%\",\n",
      "      \"Precision\": 0.9508602403959463,\n",
      "      \"Recall\": 0.27413875110416525,\n",
      "      \"Lift\": 1.0965657726919027\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"30%\",\n",
      "      \"Precision\": 0.9474614553667878,\n",
      "      \"Recall\": 0.32778419514846774,\n",
      "      \"Lift\": 1.0926461731825565\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v1_baseline_metrics.json\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"split\": \"val\",\n",
      "  \"best_val_pr_auc\": 0.9169934267257506,\n",
      "  \"best_params\": {\n",
      "    \"learning_rate\": 0.05,\n",
      "    \"max_depth\": 4,\n",
      "    \"max_iter\": 500,\n",
      "    \"min_samples_leaf\": 20,\n",
      "    \"l2_regularization\": 0.0001,\n",
      "    \"max_bins\": 128,\n",
      "    \"random_state\": 42\n",
      "  },\n",
      "  \"pos_weight\": null,\n",
      "  \"version\": \"v1_baseline\"\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v1_baseline_tuning.json\n",
      "[v1_baseline] saved paths:\n",
      "model: /Users/jy/project_2nd/SKN23-2nd-3Team/models/ml/hgb/v1_baseline/model.pkl\n",
      "metrics: /Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb/v1_baseline/metrics.json\n",
      "figure_pr_curve: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v1_baseline/pr_curve.png\n",
      "figure_confusion_matrix_top5: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v1_baseline/confusion_matrix_top5.png\n",
      "figure_confusion_matrix_top10: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v1_baseline/confusion_matrix_top10.png\n",
      "figure_confusion_matrix_top15: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v1_baseline/confusion_matrix_top15.png\n",
      "figure_confusion_matrix_top30: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v1_baseline/confusion_matrix_top30.png\n",
      "config: /Users/jy/project_2nd/SKN23-2nd-3Team/models/configs/hgb/v1_baseline/config.json\n",
      "eval_dir: /Users/jy/project_2nd/SKN23-2nd-3Team/models/eval/mlhgb\n",
      "[v2_weighted] best_val_pr_auc: 0.9170039852496816\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"split\": \"test\",\n",
      "  \"percentiles\": [\n",
      "    {\n",
      "      \"pct\": 1,\n",
      "      \"score\": 0.9489903652474851\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 5,\n",
      "      \"score\": 0.9403639544017673\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 10,\n",
      "      \"score\": 0.9341059721506936\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 20,\n",
      "      \"score\": 0.9170798127024113\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 30,\n",
      "      \"score\": 0.8986561526690733\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 50,\n",
      "      \"score\": 0.8582652265752859\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v2_weighted_score_percentiles.json\n",
      "{\n",
      "  \"PR-AUC (Average Precision)\": 0.933277653357457,\n",
      "  \"상위 5% 정밀도 (Precision)\": 0.9671970143390297,\n",
      "  \"상위 5% 재현율 (Recall)\": 0.055763176371996105,\n",
      "  \"상위 5% 리프트 (Lift)\": 1.115405920151145,\n",
      "  \"ranking\": [\n",
      "    {\n",
      "      \"Top_K\": \"5%\",\n",
      "      \"Precision\": 0.9671970143390297,\n",
      "      \"Recall\": 0.055763176371996105,\n",
      "      \"Lift\": 1.115405920151145\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"10%\",\n",
      "      \"Precision\": 0.9625846999901797,\n",
      "      \"Recall\": 0.1110054132409232,\n",
      "      \"Lift\": 1.1100868355654454\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"15%\",\n",
      "      \"Precision\": 0.959408144559382,\n",
      "      \"Recall\": 0.16595320604289823,\n",
      "      \"Lift\": 1.1064235191152583\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"20%\",\n",
      "      \"Precision\": 0.9542374545811647,\n",
      "      \"Recall\": 0.2200856152748522,\n",
      "      \"Lift\": 1.1004604959385262\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"25%\",\n",
      "      \"Precision\": 0.9507423992458166,\n",
      "      \"Recall\": 0.27410477678874773,\n",
      "      \"Lift\": 1.0964298740957084\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"30%\",\n",
      "      \"Precision\": 0.9473305181839012,\n",
      "      \"Recall\": 0.32773889606124434,\n",
      "      \"Lift\": 1.092495171776644\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v2_weighted_metrics.json\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"split\": \"val\",\n",
      "  \"best_val_pr_auc\": 0.9170039852496816,\n",
      "  \"best_params\": {\n",
      "    \"learning_rate\": 0.07,\n",
      "    \"max_depth\": 4,\n",
      "    \"max_iter\": 500,\n",
      "    \"min_samples_leaf\": 50,\n",
      "    \"l2_regularization\": 0.001,\n",
      "    \"max_bins\": 128,\n",
      "    \"random_state\": 42\n",
      "  },\n",
      "  \"pos_weight\": 0.24358702197806958,\n",
      "  \"version\": \"v2_weighted\"\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v2_weighted_tuning.json\n",
      "[v2_weighted] saved paths:\n",
      "model: /Users/jy/project_2nd/SKN23-2nd-3Team/models/ml/hgb/v2_weighted/model.pkl\n",
      "metrics: /Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb/v2_weighted/metrics.json\n",
      "figure_pr_curve: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v2_weighted/pr_curve.png\n",
      "figure_confusion_matrix_top5: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v2_weighted/confusion_matrix_top5.png\n",
      "figure_confusion_matrix_top10: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v2_weighted/confusion_matrix_top10.png\n",
      "figure_confusion_matrix_top15: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v2_weighted/confusion_matrix_top15.png\n",
      "figure_confusion_matrix_top30: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v2_weighted/confusion_matrix_top30.png\n",
      "config: /Users/jy/project_2nd/SKN23-2nd-3Team/models/configs/hgb/v2_weighted/config.json\n",
      "eval_dir: /Users/jy/project_2nd/SKN23-2nd-3Team/models/eval/mlhgb\n",
      "[v3_leaf_es] best_val_pr_auc: 0.9172400577974087\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"split\": \"test\",\n",
      "  \"percentiles\": [\n",
      "    {\n",
      "      \"pct\": 1,\n",
      "      \"score\": 0.9727240471769205\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 5,\n",
      "      \"score\": 0.9689148996092243\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 10,\n",
      "      \"score\": 0.9659623687308027\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 20,\n",
      "      \"score\": 0.9562968477615261\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 30,\n",
      "      \"score\": 0.9460141633737437\n",
      "    },\n",
      "    {\n",
      "      \"pct\": 50,\n",
      "      \"score\": 0.9233695435614606\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v3_leaf_es_score_percentiles.json\n",
      "{\n",
      "  \"PR-AUC (Average Precision)\": 0.9334413697026368,\n",
      "  \"상위 5% 정밀도 (Precision)\": 0.9677862895305441,\n",
      "  \"상위 5% 재현율 (Recall)\": 0.05579715068741365,\n",
      "  \"상위 5% 리프트 (Lift)\": 1.1160854932137878,\n",
      "  \"ranking\": [\n",
      "    {\n",
      "      \"Top_K\": \"5%\",\n",
      "      \"Precision\": 0.9677862895305441,\n",
      "      \"Recall\": 0.05579715068741365,\n",
      "      \"Lift\": 1.1160854932137878\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"10%\",\n",
      "      \"Precision\": 0.9638613375233231,\n",
      "      \"Recall\": 0.11115263527439923,\n",
      "      \"Lift\": 1.111559099273092\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"15%\",\n",
      "      \"Precision\": 0.9589498494173104,\n",
      "      \"Recall\": 0.1658739326402573,\n",
      "      \"Lift\": 1.105894996893762\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"20%\",\n",
      "      \"Precision\": 0.954384758911912,\n",
      "      \"Recall\": 0.22011958959026975,\n",
      "      \"Lift\": 1.1006303725201776\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"25%\",\n",
      "      \"Precision\": 0.9512137638463352,\n",
      "      \"Recall\": 0.2742406740504179,\n",
      "      \"Lift\": 1.0969734684804857\n",
      "    },\n",
      "    {\n",
      "      \"Top_K\": \"30%\",\n",
      "      \"Precision\": 0.9477887983240041,\n",
      "      \"Recall\": 0.3278974428665262,\n",
      "      \"Lift\": 1.0930236766973376\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v3_leaf_es_metrics.json\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"split\": \"val\",\n",
      "  \"best_val_pr_auc\": 0.9172400577974087,\n",
      "  \"best_params\": {\n",
      "    \"learning_rate\": 0.07,\n",
      "    \"max_depth\": 4,\n",
      "    \"max_leaf_nodes\": 63,\n",
      "    \"max_iter\": 500,\n",
      "    \"min_samples_leaf\": 50,\n",
      "    \"l2_regularization\": 0.0,\n",
      "    \"max_bins\": 128,\n",
      "    \"early_stopping\": true,\n",
      "    \"validation_fraction\": 0.05,\n",
      "    \"n_iter_no_change\": 20,\n",
      "    \"random_state\": 42\n",
      "  },\n",
      "  \"pos_weight\": 2.0,\n",
      "  \"version\": \"v3_leaf_es\"\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v3_leaf_es_tuning.json\n",
      "[v3_leaf_es] saved paths:\n",
      "model: /Users/jy/project_2nd/SKN23-2nd-3Team/models/ml/hgb/v3_leaf_es/model.pkl\n",
      "metrics: /Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb/v3_leaf_es/metrics.json\n",
      "figure_pr_curve: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v3_leaf_es/pr_curve.png\n",
      "figure_confusion_matrix_top5: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v3_leaf_es/confusion_matrix_top5.png\n",
      "figure_confusion_matrix_top10: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v3_leaf_es/confusion_matrix_top10.png\n",
      "figure_confusion_matrix_top15: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v3_leaf_es/confusion_matrix_top15.png\n",
      "figure_confusion_matrix_top30: /Users/jy/project_2nd/SKN23-2nd-3Team/assets/training/hgb/v3_leaf_es/confusion_matrix_top30.png\n",
      "config: /Users/jy/project_2nd/SKN23-2nd-3Team/models/configs/hgb/v3_leaf_es/config.json\n",
      "eval_dir: /Users/jy/project_2nd/SKN23-2nd-3Team/models/eval/mlhgb\n",
      "\n",
      "===== HGB 3버전 비교 =====\n",
      "- v3_leaf_es: score=0.643266 | PR-AUC=0.933441 | R@5=0.055797 | R@10=0.111153 | R@30=0.327897 | Lift@5=1.116085 | Lift@10=1.111559\n",
      "  metrics: /Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v3_leaf_es_metrics.json\n",
      "- v2_weighted: score=0.643064 | PR-AUC=0.933278 | R@5=0.055763 | R@10=0.111005 | R@30=0.327739 | Lift@5=1.115406 | Lift@10=1.110087\n",
      "  metrics: /Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v2_weighted_metrics.json\n",
      "- v1_baseline: score=0.643016 | PR-AUC=0.933225 | R@5=0.055707 | R@10=0.111005 | R@30=0.327784 | Lift@5=1.114273 | Lift@10=1.110087\n",
      "  metrics: /Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v1_baseline_metrics.json\n",
      "\n",
      "===== 최종 선택 =====\n",
      "{\n",
      "  \"model_id\": \"ml__hgb\",\n",
      "  \"selected_version\": \"v3_leaf_es\",\n",
      "  \"selection_score\": 0.6432662371981482,\n",
      "  \"criteria\": {\n",
      "    \"weights\": {\n",
      "      \"PR-AUC\": 0.55,\n",
      "      \"Recall@10\": 0.2,\n",
      "      \"Recall@30\": 0.15,\n",
      "      \"Recall@5\": 0.05,\n",
      "      \"Lift@10\": 0.03,\n",
      "      \"Lift@5\": 0.02\n",
      "    },\n",
      "    \"notes\": \"VAL로 튜닝하고 TEST는 1회만 평가한 결과(metrics.json) 기반으로 최종 선택\"\n",
      "  },\n",
      "  \"winner_metrics_path\": \"/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_v3_leaf_es_metrics.json\"\n",
      "}\n",
      "/Users/jy/project_2nd/SKN23-2nd-3Team/models/metrics/hgb_final_selection.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/jy/project_2nd/SKN23-2nd-3Team\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from app.utils.save import save_model_and_artifacts\n",
    "\n",
    "try:\n",
    "    from app.utils.plotting import configure_matplotlib_korean\n",
    "    configure_matplotlib_korean()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# utils: 저장/출력\n",
    "\n",
    "def _stem_from_model_id(model_id: str) -> str:\n",
    "    if model_id.startswith(\"dl__mlp_\"):\n",
    "        return \"mlp_\" + model_id.split(\"dl__mlp_\", 1)[1]\n",
    "    if model_id.startswith(\"ml__\"):\n",
    "        return model_id.split(\"ml__\", 1)[1]\n",
    "    if model_id.startswith(\"dl__\"):\n",
    "        return model_id.split(\"dl__\", 1)[1]\n",
    "    return model_id\n",
    "\n",
    "def save_json_to_metrics_dir(stem: str, filename: str, payload: dict):\n",
    "    metrics_dir = PROJECT_ROOT / \"models\" / \"metrics\"\n",
    "    metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = metrics_dir / f\"{stem}_{filename}.json\"\n",
    "    out_path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(json.dumps(payload, ensure_ascii=False, indent=2))\n",
    "    print(str(out_path))\n",
    "    return out_path\n",
    "\n",
    "def score_percentiles_payload(model_id: str, split: str, y_prob, pcts=(1, 5, 10, 20, 30, 50)):\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    percentiles = [{\"pct\": int(p), \"score\": float(np.quantile(y_prob, 1.0 - p / 100.0))} for p in pcts]\n",
    "    return {\"model_id\": model_id, \"split\": split, \"percentiles\": percentiles}\n",
    "\n",
    "def build_ranking_metrics(y_true, y_prob, k_list=(5, 10, 15, 20, 25, 30)):\n",
    "    y_true = np.asarray(y_true).astype(int).reshape(-1)\n",
    "    y_prob = np.asarray(y_prob).astype(float).reshape(-1)\n",
    "\n",
    "    pr_auc = float(average_precision_score(y_true, y_prob))\n",
    "\n",
    "    df_rank = pd.DataFrame({\"y\": y_true, \"score\": y_prob}).sort_values(\"score\", ascending=False)\n",
    "    base_rate = float(df_rank[\"y\"].mean())\n",
    "    total_pos = float(df_rank[\"y\"].sum())\n",
    "    n_total = len(df_rank)\n",
    "\n",
    "    ranking = []\n",
    "    for k in k_list:\n",
    "        n_sel = max(int(np.floor(n_total * k / 100)), 1)\n",
    "        selected = df_rank.iloc[:n_sel]\n",
    "\n",
    "        precision_k = float(selected[\"y\"].mean())\n",
    "        recall_k = float(selected[\"y\"].sum() / (total_pos + 1e-12))\n",
    "        lift_k = float(precision_k / base_rate) if base_rate > 0 else 0.0\n",
    "\n",
    "        ranking.append({\"Top_K\": f\"{k}%\", \"Precision\": precision_k, \"Recall\": recall_k, \"Lift\": lift_k})\n",
    "\n",
    "    return {\n",
    "        \"PR-AUC (Average Precision)\": pr_auc,\n",
    "        \"상위 5% 정밀도 (Precision)\": ranking[0][\"Precision\"],\n",
    "        \"상위 5% 재현율 (Recall)\": ranking[0][\"Recall\"],\n",
    "        \"상위 5% 리프트 (Lift)\": ranking[0][\"Lift\"],\n",
    "        \"ranking\": ranking,\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, labels=(\"비이탈(m1)\", \"이탈(m2)\"), cmap=\"Blues\"):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_pred = np.asarray(y_pred).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(cm, cmap=cmap, interpolation=\"nearest\", aspect=\"equal\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted (예측값)\")\n",
    "    ax.set_ylabel(\"Actual (실제값)\")\n",
    "\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    thresh = cm.max() / 2.0 if cm.size else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(\n",
    "                j, i, f\"{cm[i, j]}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                fontsize=12,\n",
    "            )\n",
    "\n",
    "    ax.set_xlim(-0.5, cm.shape[1] - 0.5)\n",
    "    ax.set_ylim(cm.shape[0] - 0.5, -0.5)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def threshold_topk(y_prob, k_pct: int) -> float:\n",
    "    y_prob = np.asarray(y_prob, dtype=float).reshape(-1)\n",
    "    order = np.argsort(-y_prob)\n",
    "    n_sel = max(int(np.floor(len(y_prob) * k_pct / 100)), 1)\n",
    "    return float(y_prob[order[n_sel - 1]])\n",
    "\n",
    "def make_figures(test_true, test_prob, pr_auc_val, k_list=(5, 10, 15, 30)):\n",
    "    precision, recall, _ = precision_recall_curve(test_true, test_prob)\n",
    "    fig_pr, ax_pr = plt.subplots(figsize=(6, 5))\n",
    "    ax_pr.plot(recall, precision, lw=2, label=f\"PR-AUC = {pr_auc_val:.5f}\")\n",
    "    ax_pr.set_xlabel(\"Recall\")\n",
    "    ax_pr.set_ylabel(\"Precision\")\n",
    "    ax_pr.set_title(\"Precision-Recall Curve\")\n",
    "    ax_pr.legend()\n",
    "    ax_pr.grid(alpha=0.3)\n",
    "    fig_pr.tight_layout()\n",
    "\n",
    "    figures = {\"pr_curve\": fig_pr}\n",
    "    for k in k_list:\n",
    "        thr = threshold_topk(test_prob, k)\n",
    "        y_pred_k = (np.asarray(test_prob) >= thr).astype(int)\n",
    "        figures[f\"confusion_matrix_top{k}\"] = plot_confusion_matrix(\n",
    "            test_true,\n",
    "            y_pred_k,\n",
    "            title=f\"Confusion Matrix (Top {k}%, thr={thr:.5f})\",\n",
    "            labels=(\"비이탈(m1)\", \"이탈(m2)\"),\n",
    "            cmap=\"Blues\",\n",
    "        )\n",
    "    return figures\n",
    "\n",
    "\n",
    "\n",
    "# data load / split\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "features = pd.read_parquet(DATA_DIR / \"features_ml_clean.parquet\")\n",
    "labels = pd.read_parquet(DATA_DIR / \"labels.parquet\")\n",
    "\n",
    "features[\"user_id\"] = features[\"user_id\"].astype(str)\n",
    "labels[\"user_id\"] = labels[\"user_id\"].astype(str)\n",
    "\n",
    "df = features.merge(\n",
    "    labels[[\"user_id\", \"anchor_time\", \"label\", \"split\"]],\n",
    "    on=[\"user_id\", \"anchor_time\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "df[\"y\"] = (df[\"label\"] == \"m2\").astype(int)\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [\"user_id\", \"anchor_time\", \"label\", \"split\", \"y\"]]\n",
    "\n",
    "train_df = df[df[\"split\"] == \"train\"]\n",
    "val_df = df[df[\"split\"] == \"val\"]\n",
    "test_df = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "X_train, y_train = train_df[feature_cols], train_df[\"y\"].to_numpy()\n",
    "X_val, y_val = val_df[feature_cols], val_df[\"y\"].to_numpy()\n",
    "X_test, y_test = test_df[feature_cols], test_df[\"y\"].to_numpy()\n",
    "\n",
    "X_tv = pd.concat([train_df[feature_cols], val_df[feature_cols]], axis=0)\n",
    "y_tv = pd.concat([train_df[\"y\"], val_df[\"y\"]], axis=0).to_numpy()\n",
    "\n",
    "\n",
    "def fit_predict(model_params: dict, use_weights: bool, pos_weight: float | None):\n",
    "    model = HistGradientBoostingClassifier(**model_params)\n",
    "    if use_weights:\n",
    "        w = np.ones_like(y_train, dtype=float)\n",
    "        w[y_train == 1] = float(pos_weight)\n",
    "        model.fit(X_train, y_train, sample_weight=w)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    val_prob = model.predict_proba(X_val)[:, 1]\n",
    "    val_pr_auc = float(average_precision_score(y_val, val_prob))\n",
    "    return model, val_pr_auc\n",
    "\n",
    "\n",
    "def tune_version(version_name: str, search_space: dict, n_trials=25, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    best = {\"val_pr_auc\": -1.0, \"params\": None}\n",
    "\n",
    "    for _ in range(n_trials):\n",
    "        params = {}\n",
    "        for k, choices in search_space.items():\n",
    "            choice = rng.choice(choices)\n",
    "            if k in {\"max_iter\", \"min_samples_leaf\", \"max_bins\", \"max_leaf_nodes\", \"n_iter_no_change\"}:\n",
    "                params[k] = int(choice)\n",
    "            elif k == \"max_depth\":\n",
    "                params[k] = None if choice is None else int(choice)\n",
    "            elif k == \"early_stopping\":\n",
    "                params[k] = bool(choice)\n",
    "            elif k in {\"learning_rate\", \"l2_regularization\", \"validation_fraction\"}:\n",
    "                params[k] = float(choice)\n",
    "            elif k == \"pos_weight\":\n",
    "                params[k] = float(choice)\n",
    "            else:\n",
    "                params[k] = choice\n",
    "\n",
    "        pos_weight = params.pop(\"pos_weight\", None)\n",
    "        use_weights = pos_weight is not None and pos_weight > 1.0\n",
    "\n",
    "        base_params = dict(params)\n",
    "        base_params[\"random_state\"] = 42\n",
    "\n",
    "        model, val_pr_auc = fit_predict(base_params, use_weights=use_weights, pos_weight=pos_weight)\n",
    "\n",
    "        if val_pr_auc > best[\"val_pr_auc\"]:\n",
    "            best = {\"val_pr_auc\": val_pr_auc, \"params\": dict(base_params), \"pos_weight\": pos_weight}\n",
    "\n",
    "    print(f\"[{version_name}] best_val_pr_auc:\", best[\"val_pr_auc\"])\n",
    "    return best\n",
    "\n",
    "\n",
    "def train_eval_save(version_name: str, best: dict, model_id=\"ml__hgb\", split=\"test\"):\n",
    "    pos_weight = best.get(\"pos_weight\", None)\n",
    "    use_weights = pos_weight is not None and pos_weight > 1.0\n",
    "\n",
    "    model_params = dict(best[\"params\"])\n",
    "\n",
    "    hgb = HistGradientBoostingClassifier(**model_params)\n",
    "\n",
    "    if use_weights:\n",
    "        y_tv_arr = np.asarray(y_tv).astype(int)\n",
    "        w_tv = np.ones_like(y_tv_arr, dtype=float)\n",
    "        w_tv[y_tv_arr == 1] = float(pos_weight)\n",
    "        hgb.fit(X_tv, y_tv_arr, sample_weight=w_tv)\n",
    "    else:\n",
    "        hgb.fit(X_tv, np.asarray(y_tv).astype(int))\n",
    "\n",
    "    test_prob = hgb.predict_proba(X_test)[:, 1]\n",
    "    test_true = np.asarray(y_test).astype(int)\n",
    "\n",
    "    metrics_payload = build_ranking_metrics(test_true, test_prob)\n",
    "    pr_auc_val = float(metrics_payload[\"PR-AUC (Average Precision)\"])\n",
    "\n",
    "    stem = f\"{_stem_from_model_id(model_id)}_{version_name}\"\n",
    "\n",
    "    sp = score_percentiles_payload(model_id, split, test_prob)\n",
    "    save_json_to_metrics_dir(stem, \"score_percentiles\", sp)\n",
    "\n",
    "    save_json_to_metrics_dir(stem, \"metrics\", metrics_payload)\n",
    "\n",
    "    tuning_payload = {\n",
    "        \"model_id\": model_id,\n",
    "        \"split\": \"val\",\n",
    "        \"best_val_pr_auc\": float(best[\"val_pr_auc\"]),\n",
    "        \"best_params\": best[\"params\"],\n",
    "        \"pos_weight\": best.get(\"pos_weight\", None),\n",
    "        \"version\": version_name,\n",
    "    }\n",
    "    save_json_to_metrics_dir(stem, \"tuning\", tuning_payload)\n",
    "\n",
    "    figures = make_figures(test_true, test_prob, pr_auc_val, k_list=(5, 10, 15, 30))\n",
    "\n",
    "    saved = save_model_and_artifacts(\n",
    "        model=hgb,\n",
    "        model_name=\"hgb\",\n",
    "        model_type=\"ml\",\n",
    "        model_id=model_id,\n",
    "        split=split,\n",
    "        metrics=metrics_payload,\n",
    "        y_true=test_true,\n",
    "        y_prob=np.asarray(test_prob).astype(float),\n",
    "        version=version_name,\n",
    "        scaler=None,\n",
    "        figures=figures,\n",
    "    )\n",
    "\n",
    "    plt.close(figures[\"pr_curve\"])\n",
    "    for k in (5, 10, 15, 30):\n",
    "        plt.close(figures[f\"confusion_matrix_top{k}\"])\n",
    "\n",
    "    print(f\"[{version_name}] saved paths:\")\n",
    "    for k, v in saved.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    return {\"version\": version_name, \"test_pr_auc\": pr_auc_val, \"saved\": saved}\n",
    "\n",
    "\n",
    "\n",
    "# Version 1: baseline\n",
    "\n",
    "space_v1 = {\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"max_iter\": [300, 500],\n",
    "    \"min_samples_leaf\": [20, 50, 100],\n",
    "    \"l2_regularization\": [0.0, 1e-4, 1e-3, 1e-2],\n",
    "    \"max_bins\": [128, 255],\n",
    "}\n",
    "\n",
    "best_v1 = tune_version(\"v1_baseline\", space_v1, n_trials=25, seed=42)\n",
    "out_v1 = train_eval_save(\"v1_baseline\", best_v1)\n",
    "\n",
    "\n",
    "\n",
    "# Version 2: sample_weight(pos_weight)\n",
    "\n",
    "neg = float((y_train == 0).sum())\n",
    "pos = float((y_train == 1).sum())\n",
    "ratio = neg / (pos + 1e-12)\n",
    "\n",
    "space_v2 = {\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"max_iter\": [300, 500],\n",
    "    \"min_samples_leaf\": [20, 50, 100],\n",
    "    \"l2_regularization\": [0.0, 1e-4, 1e-3, 1e-2],\n",
    "    \"max_bins\": [128, 255],\n",
    "    \"pos_weight\": [1.0, 2.0, 5.0, 10.0, ratio],\n",
    "}\n",
    "\n",
    "best_v2 = tune_version(\"v2_weighted\", space_v2, n_trials=25, seed=43)\n",
    "out_v2 = train_eval_save(\"v2_weighted\", best_v2)\n",
    "\n",
    "\n",
    "\n",
    "# Version 3: weight + max_leaf_nodes + early_stopping\n",
    "\n",
    "space_v3 = {\n",
    "    \"learning_rate\": [0.02, 0.03, 0.05, 0.07],\n",
    "    \"max_depth\": [None, 3, 4, 5, 6],\n",
    "    \"max_leaf_nodes\": [15, 31, 63, 127],\n",
    "    \"max_iter\": [500, 800],\n",
    "    \"min_samples_leaf\": [20, 50, 100],\n",
    "    \"l2_regularization\": [0.0, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    \"max_bins\": [128, 255],\n",
    "    \"early_stopping\": [True],\n",
    "    \"validation_fraction\": [0.05, 0.1],\n",
    "    \"n_iter_no_change\": [10, 20],\n",
    "    \"pos_weight\": [2.0, 5.0, 10.0, ratio],\n",
    "}\n",
    "\n",
    "best_v3 = tune_version(\"v3_leaf_es\", space_v3, n_trials=25, seed=44)\n",
    "out_v3 = train_eval_save(\"v3_leaf_es\", best_v3)\n",
    "\n",
    "def _get_rank_item(metrics_payload: dict, k_pct: int):\n",
    "    target = f\"{k_pct}%\"\n",
    "    for row in metrics_payload.get(\"ranking\", []):\n",
    "        if row.get(\"Top_K\") == target:\n",
    "            return row\n",
    "    return None\n",
    "\n",
    "def _selection_score(metrics_payload: dict):\n",
    "    pr = float(metrics_payload.get(\"PR-AUC (Average Precision)\", 0.0))\n",
    "\n",
    "    r5 = _get_rank_item(metrics_payload, 5)\n",
    "    r10 = _get_rank_item(metrics_payload, 10)\n",
    "    r30 = _get_rank_item(metrics_payload, 30)\n",
    "\n",
    "    recall5 = float(r5[\"Recall\"]) if r5 else 0.0\n",
    "    recall10 = float(r10[\"Recall\"]) if r10 else 0.0\n",
    "    recall30 = float(r30[\"Recall\"]) if r30 else 0.0\n",
    "\n",
    "    lift5 = float(r5[\"Lift\"]) if r5 else 0.0\n",
    "    lift10 = float(r10[\"Lift\"]) if r10 else 0.0\n",
    "\n",
    "    # 기본 점수 (PR-AUC 중심 + recall@10/30 강조 + lift 약간)\n",
    "    score = (\n",
    "        0.55 * pr\n",
    "        + 0.20 * recall10\n",
    "        + 0.15 * recall30\n",
    "        + 0.05 * recall5\n",
    "        + 0.03 * lift10\n",
    "        + 0.02 * lift5\n",
    "    )\n",
    "    return float(score)\n",
    "\n",
    "def summarize_version(version_obj):\n",
    "    version = version_obj[\"version\"]\n",
    "    # 우리가 train_eval_save에서 metrics를 metrics_dir에 저장했지만,\n",
    "    # 여기서는 빠르게 다시 계산/기록하려고 out_v*에 test_pr_auc만 담겨있음.\n",
    "    # 따라서 metrics_payload는 파일로 저장된 것에서 다시 읽는 대신\n",
    "    # train_eval_save 내부에서 metrics_payload도 같이 반환하도록 하는 게 가장 깔끔하지만,\n",
    "    # 지금은 saved dict 기반으로 metrics 파일 경로를 찾아 읽도록 처리한다.\n",
    "    return version\n",
    "\n",
    "# metrics 파일 다시 로드해서 비교 (버전별 stem 규칙: hgb_<version>_metrics.json)\n",
    "METRICS_DIR = PROJECT_ROOT / \"models\" / \"metrics\"\n",
    "\n",
    "def load_metrics_for(version_name: str, model_id=\"ml__hgb\"):\n",
    "    stem = f\"{_stem_from_model_id(model_id)}_{version_name}\"\n",
    "    path = METRICS_DIR / f\"{stem}_metrics.json\"\n",
    "    payload = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    return path, payload\n",
    "\n",
    "candidates = []\n",
    "for v in [\"v1_baseline\", \"v2_weighted\", \"v3_leaf_es\"]:\n",
    "    m_path, m_payload = load_metrics_for(v, model_id=\"ml__hgb\")\n",
    "    score = _selection_score(m_payload)\n",
    "\n",
    "    r5 = _get_rank_item(m_payload, 5) or {}\n",
    "    r10 = _get_rank_item(m_payload, 10) or {}\n",
    "    r30 = _get_rank_item(m_payload, 30) or {}\n",
    "\n",
    "    candidates.append({\n",
    "        \"version\": v,\n",
    "        \"score_for_selection\": score,\n",
    "        \"pr_auc\": float(m_payload.get(\"PR-AUC (Average Precision)\", 0.0)),\n",
    "        \"recall@5\": float(r5.get(\"Recall\", 0.0)),\n",
    "        \"recall@10\": float(r10.get(\"Recall\", 0.0)),\n",
    "        \"recall@30\": float(r30.get(\"Recall\", 0.0)),\n",
    "        \"lift@5\": float(r5.get(\"Lift\", 0.0)),\n",
    "        \"lift@10\": float(r10.get(\"Lift\", 0.0)),\n",
    "        \"metrics_path\": str(m_path),\n",
    "    })\n",
    "\n",
    "# 점수 기준으로 정렬\n",
    "candidates_sorted = sorted(candidates, key=lambda x: x[\"score_for_selection\"], reverse=True)\n",
    "\n",
    "# 콘솔 비교표 출력\n",
    "print(\"\\n===== HGB 3버전 비교 =====\")\n",
    "for row in candidates_sorted:\n",
    "    print(\n",
    "        f\"- {row['version']}: \"\n",
    "        f\"score={row['score_for_selection']:.6f} | \"\n",
    "        f\"PR-AUC={row['pr_auc']:.6f} | \"\n",
    "        f\"R@5={row['recall@5']:.6f} | R@10={row['recall@10']:.6f} | R@30={row['recall@30']:.6f} | \"\n",
    "        f\"Lift@5={row['lift@5']:.6f} | Lift@10={row['lift@10']:.6f}\\n\"\n",
    "        f\"  metrics: {row['metrics_path']}\"\n",
    "    )\n",
    "\n",
    "winner = candidates_sorted[0]\n",
    "\n",
    "final_selection = {\n",
    "    \"model_id\": \"ml__hgb\",\n",
    "    \"selected_version\": winner[\"version\"],\n",
    "    \"selection_score\": winner[\"score_for_selection\"],\n",
    "    \"criteria\": {\n",
    "        \"weights\": {\n",
    "            \"PR-AUC\": 0.55,\n",
    "            \"Recall@10\": 0.20,\n",
    "            \"Recall@30\": 0.15,\n",
    "            \"Recall@5\": 0.05,\n",
    "            \"Lift@10\": 0.03,\n",
    "            \"Lift@5\": 0.02,\n",
    "        },\n",
    "        \"notes\": \"VAL로 튜닝하고 TEST는 1회만 평가한 결과(metrics.json) 기반으로 최종 선택\",\n",
    "    },\n",
    "    \"winner_metrics_path\": winner[\"metrics_path\"],\n",
    "}\n",
    "\n",
    "final_path = METRICS_DIR / \"hgb_final_selection.json\"\n",
    "final_path.write_text(json.dumps(final_selection, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\n===== 최종 선택 =====\")\n",
    "print(json.dumps(final_selection, ensure_ascii=False, indent=2))\n",
    "print(str(final_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439b11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
